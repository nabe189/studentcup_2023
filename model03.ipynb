{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv', index_col=0)\n",
    "test = pd.read_csv('data/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- categoryは全部one-hotで表現\n",
    "- yaerで2030年以降のものがある\n",
    "    - おそらくタイポ\n",
    "    - -1000してあげるのが良い\n",
    "    - lightgbm使うのでその他の処理は行わない\n",
    "- conditionは1~6で評価\n",
    "- odometer\n",
    "    - 絶対値を取る\n",
    "    - 1はnullにしてあげる(元々odometer=1のデータはない)\n",
    "    - 1e6を超える場合は10で割る\n",
    "- cylinders, transmission, typeのotherはnullにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    #year\n",
    "    df.loc[((df['year']>2030) & (df['year']<3000)) | (df['year']>=3000), 'year'] -= 1000\n",
    "\n",
    "    #condition\n",
    "    condition_dict = {'excellent':4, 'fair':2, 'good':3, 'like new':5, 'salvage':1, 'new':6}\n",
    "    df['condition'] = df['condition'].apply(lambda x: condition_dict[x])\n",
    "\n",
    "    #odometer\n",
    "    def set_odometer(x):\n",
    "        x = abs(x)\n",
    "        if x==1:\n",
    "            return None\n",
    "        if x>1e6:\n",
    "            x = x//10\n",
    "        return x\n",
    "    df['odometer'] = [set_odometer(x) for x in df['odometer'].values]\n",
    "\n",
    "    #size\n",
    "    size_dict = {'mid-size':3, 'full-size':4, 'sub-compact':1, 'compact':2}\n",
    "    df['size'] = [size_dict[unicodedata.normalize('NFKC', x).lower().replace('ー', '-').replace('−', '-')] if type(x)==str else None for x in df['size'].values]\n",
    "\n",
    "    #categorical data\n",
    "    categoly_calumns = ['region', 'manufacturer', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'type', 'paint_color', 'state']\n",
    "    for cat in categoly_calumns:\n",
    "        df[cat] = [unicodedata.normalize('NFKC', x).lower() if type(x)==str else None for x in df[cat].values]\n",
    "\n",
    "    #otherをnullにする\n",
    "    for cat in ['cylinders', 'transmission', 'type']:\n",
    "        df[cat] = [x if x!='other' else None for x in df[cat].values]\n",
    "\n",
    "    df = pd.get_dummies(df, columns=categoly_calumns) #one-hot vectorize\n",
    "\n",
    "    df['odometer'] = df['odometer'].fillna(df['odometer'].mean())\n",
    "    \n",
    "    for cat in df.columns:\n",
    "        if len(df[df[cat].isnull()]) == 0:\n",
    "            df[cat] = df[cat].astype(int) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>condition</th>\n",
       "      <th>odometer</th>\n",
       "      <th>size</th>\n",
       "      <th>region_abilene</th>\n",
       "      <th>region_akron / canton</th>\n",
       "      <th>region_albany</th>\n",
       "      <th>region_albuquerque</th>\n",
       "      <th>region_altoona-johnstown</th>\n",
       "      <th>region_amarillo</th>\n",
       "      <th>...</th>\n",
       "      <th>state_sd</th>\n",
       "      <th>state_tn</th>\n",
       "      <th>state_tx</th>\n",
       "      <th>state_ut</th>\n",
       "      <th>state_va</th>\n",
       "      <th>state_vt</th>\n",
       "      <th>state_wa</th>\n",
       "      <th>state_wi</th>\n",
       "      <th>state_wv</th>\n",
       "      <th>state_wy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1949</td>\n",
       "      <td>4</td>\n",
       "      <td>115148</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>172038</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>3</td>\n",
       "      <td>152492</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>104118</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>144554</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 520 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  condition  odometer  size  region_abilene  region_akron / canton  \\\n",
       "0  1949          4    115148     3               0                      0   \n",
       "1  2013          2    172038     4               0                      0   \n",
       "2  1998          3    152492     4               0                      0   \n",
       "3  2014          4    104118     3               0                      0   \n",
       "4  2005          4    144554     3               0                      0   \n",
       "\n",
       "   region_albany  region_albuquerque  region_altoona-johnstown  \\\n",
       "0              0                   0                         0   \n",
       "1              0                   0                         0   \n",
       "2              0                   0                         0   \n",
       "3              1                   0                         0   \n",
       "4              0                   0                         0   \n",
       "\n",
       "   region_amarillo  ...  state_sd  state_tn  state_tx  state_ut  state_va  \\\n",
       "0                0  ...         0         0         0         0         0   \n",
       "1                0  ...         0         0         0         0         0   \n",
       "2                0  ...         0         0         0         0         0   \n",
       "3                0  ...         0         0         0         0         0   \n",
       "4                0  ...         0         0         0         0         0   \n",
       "\n",
       "   state_vt  state_wa  state_wi  state_wv  state_wy  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 520 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train, test], ignore_index=True).drop(['price'], axis=1)\n",
    "df_processed = preprocess(df)\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_processed[:len(train)].values\n",
    "y = train['price'].values\n",
    "X_test = df_processed[len(train):].values\n",
    "\n",
    "features = df_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 61.1326 - val_loss: 54.9044\n",
      "Epoch 2/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 53.5586 - val_loss: 51.8289\n",
      "Epoch 3/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.9511 - val_loss: 51.1566\n",
      "Epoch 4/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.9873 - val_loss: 51.5263\n",
      "Epoch 5/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.5522 - val_loss: 52.2536\n",
      "Epoch 6/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.4306 - val_loss: 51.1546\n",
      "Epoch 7/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.4982 - val_loss: 54.5120\n",
      "Epoch 8/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.3064 - val_loss: 51.9182\n",
      "Epoch 9/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.3284 - val_loss: 51.4841\n",
      "Epoch 10/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.4549 - val_loss: 53.0758\n",
      "Epoch 11/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.3372 - val_loss: 56.3166\n",
      "Epoch 12/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.3457 - val_loss: 51.4433\n",
      "Epoch 13/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.1622 - val_loss: 51.1646\n",
      "Epoch 14/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 51.7930 - val_loss: 52.1800\n",
      "Epoch 15/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 51.7690 - val_loss: 51.0819\n",
      "Epoch 16/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.0806 - val_loss: 52.6593\n",
      "Epoch 17/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 51.8974 - val_loss: 52.8327\n",
      "Epoch 18/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 51.8272 - val_loss: 56.9699\n",
      "Epoch 19/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.2162 - val_loss: 51.1438\n",
      "Epoch 20/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 51.7111 - val_loss: 51.1537\n",
      "Epoch 21/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 51.9794 - val_loss: 53.1199\n",
      "Epoch 22/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 51.9974 - val_loss: 52.0850\n",
      "Epoch 23/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 51.9898 - val_loss: 52.4918\n",
      "Epoch 24/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6078 - val_loss: 50.8904\n",
      "Epoch 25/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5975 - val_loss: 50.8816\n",
      "Epoch 26/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 51.6594 - val_loss: 51.9561\n",
      "Epoch 27/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.8412 - val_loss: 50.9130\n",
      "Epoch 28/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6628 - val_loss: 51.0957\n",
      "Epoch 29/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 51.8563 - val_loss: 51.6986\n",
      "Epoch 30/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6198 - val_loss: 51.1884\n",
      "Epoch 31/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4434 - val_loss: 51.3546\n",
      "Epoch 32/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5784 - val_loss: 52.6937\n",
      "Epoch 33/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5701 - val_loss: 52.7472\n",
      "Epoch 34/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3865 - val_loss: 51.3007\n",
      "Epoch 35/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3825 - val_loss: 51.0385\n",
      "Epoch 36/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4284 - val_loss: 50.9058\n",
      "Epoch 37/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5385 - val_loss: 51.0787\n",
      "Epoch 38/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3337 - val_loss: 50.8326\n",
      "Epoch 39/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3526 - val_loss: 50.8174\n",
      "Epoch 40/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5243 - val_loss: 50.8035\n",
      "Epoch 41/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5579 - val_loss: 51.8133\n",
      "Epoch 42/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4296 - val_loss: 50.7728\n",
      "Epoch 43/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5924 - val_loss: 50.8061\n",
      "Epoch 44/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3033 - val_loss: 51.3608\n",
      "Epoch 45/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3505 - val_loss: 51.0546\n",
      "Epoch 46/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6570 - val_loss: 51.3247\n",
      "Epoch 47/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3824 - val_loss: 51.4285\n",
      "Epoch 48/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1579 - val_loss: 50.6605\n",
      "Epoch 49/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1185 - val_loss: 51.9578\n",
      "Epoch 50/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.2267 - val_loss: 50.7298\n",
      "Epoch 51/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0979 - val_loss: 51.1634\n",
      "Epoch 52/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1978 - val_loss: 54.8910\n",
      "Epoch 53/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3271 - val_loss: 52.5956\n",
      "Epoch 54/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3235 - val_loss: 50.5626\n",
      "Epoch 55/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1703 - val_loss: 50.7738\n",
      "Epoch 56/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1248 - val_loss: 50.9851\n",
      "Epoch 57/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1967 - val_loss: 50.5941\n",
      "Epoch 58/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9965 - val_loss: 50.5012\n",
      "Epoch 59/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0521 - val_loss: 50.8546\n",
      "Epoch 60/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1156 - val_loss: 50.6288\n",
      "Epoch 61/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9925 - val_loss: 51.7691\n",
      "Epoch 62/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0838 - val_loss: 51.4619\n",
      "Epoch 63/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0958 - val_loss: 50.5271\n",
      "Epoch 64/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9989 - val_loss: 50.8886\n",
      "Epoch 65/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1655 - val_loss: 51.2362\n",
      "Epoch 66/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0310 - val_loss: 50.4987\n",
      "Epoch 67/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1587 - val_loss: 50.5202\n",
      "Epoch 68/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9055 - val_loss: 53.5759\n",
      "Epoch 69/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9161 - val_loss: 50.7440\n",
      "Epoch 70/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.8993 - val_loss: 51.5927\n",
      "Epoch 71/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.8182 - val_loss: 51.6478\n",
      "Epoch 72/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.6861 - val_loss: 50.1512\n",
      "Epoch 73/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.5557 - val_loss: 51.3694\n",
      "Epoch 74/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.6753 - val_loss: 49.9992\n",
      "Epoch 75/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.6448 - val_loss: 51.0733\n",
      "Epoch 76/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.6765 - val_loss: 50.0898\n",
      "Epoch 77/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.1642 - val_loss: 52.6801\n",
      "Epoch 78/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.8408 - val_loss: 53.0102\n",
      "Epoch 79/10000\n",
      "646/646 [==============================] - 4s 7ms/step - loss: 50.5995 - val_loss: 50.5378\n",
      "Epoch 80/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.2065 - val_loss: 50.7383\n",
      "Epoch 81/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.3163 - val_loss: 49.7628\n",
      "Epoch 82/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.4721 - val_loss: 55.6680\n",
      "Epoch 83/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.1844 - val_loss: 51.7879\n",
      "Epoch 84/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.2253 - val_loss: 50.4386\n",
      "Epoch 85/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.3061 - val_loss: 49.9100\n",
      "Epoch 86/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0997 - val_loss: 52.6010\n",
      "Epoch 87/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.1490 - val_loss: 50.5627\n",
      "Epoch 88/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.2887 - val_loss: 50.3163\n",
      "Epoch 89/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0873 - val_loss: 49.6249\n",
      "Epoch 90/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0815 - val_loss: 51.0712\n",
      "Epoch 91/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0062 - val_loss: 49.8411\n",
      "Epoch 92/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0912 - val_loss: 52.3033\n",
      "Epoch 93/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.2496 - val_loss: 49.9649\n",
      "Epoch 94/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.8072 - val_loss: 50.3460\n",
      "Epoch 95/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0640 - val_loss: 49.7219\n",
      "Epoch 96/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.4481 - val_loss: 50.6976\n",
      "Epoch 97/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.2286 - val_loss: 50.2282\n",
      "Epoch 98/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.1340 - val_loss: 50.3601\n",
      "Epoch 99/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.2394 - val_loss: 51.1866\n",
      "Epoch 100/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0217 - val_loss: 50.6444\n",
      "Epoch 101/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0401 - val_loss: 49.8839\n",
      "Epoch 102/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.9050 - val_loss: 50.2941\n",
      "Epoch 103/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0033 - val_loss: 50.1837\n",
      "Epoch 104/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.7986 - val_loss: 49.1267\n",
      "Epoch 105/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6083 - val_loss: 48.8178\n",
      "Epoch 106/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.9034 - val_loss: 53.3223\n",
      "Epoch 107/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.9263 - val_loss: 50.5332\n",
      "Epoch 108/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.8537 - val_loss: 49.3729\n",
      "Epoch 109/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4466 - val_loss: 49.1395\n",
      "Epoch 110/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.4454 - val_loss: 50.0283\n",
      "Epoch 111/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4986 - val_loss: 49.4753\n",
      "Epoch 112/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.7047 - val_loss: 51.7912\n",
      "Epoch 113/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6534 - val_loss: 49.4473\n",
      "Epoch 114/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4406 - val_loss: 50.3158\n",
      "Epoch 115/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3230 - val_loss: 48.9872\n",
      "Epoch 116/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4845 - val_loss: 49.1687\n",
      "Epoch 117/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2088 - val_loss: 49.5388\n",
      "Epoch 118/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2489 - val_loss: 49.6343\n",
      "Epoch 119/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1126 - val_loss: 49.5690\n",
      "Epoch 120/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4651 - val_loss: 50.0334\n",
      "Epoch 121/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4709 - val_loss: 48.4859\n",
      "Epoch 122/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.7461 - val_loss: 49.2199\n",
      "Epoch 123/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4583 - val_loss: 49.9095\n",
      "Epoch 124/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2728 - val_loss: 50.9447\n",
      "Epoch 125/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4947 - val_loss: 49.1953\n",
      "Epoch 126/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6652 - val_loss: 49.4533\n",
      "Epoch 127/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2800 - val_loss: 50.0546\n",
      "Epoch 128/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1915 - val_loss: 51.3817\n",
      "Epoch 129/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3225 - val_loss: 49.0852\n",
      "Epoch 130/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0634 - val_loss: 50.0525\n",
      "Epoch 131/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0187 - val_loss: 49.6575\n",
      "Epoch 132/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3093 - val_loss: 48.7801\n",
      "Epoch 133/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2031 - val_loss: 48.9231\n",
      "Epoch 134/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2292 - val_loss: 51.1747\n",
      "Epoch 135/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8303 - val_loss: 49.9443\n",
      "Epoch 136/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2634 - val_loss: 49.0351\n",
      "Epoch 137/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2675 - val_loss: 51.0086\n",
      "Epoch 138/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9372 - val_loss: 51.8610\n",
      "Epoch 139/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0585 - val_loss: 50.5993\n",
      "Epoch 140/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2333 - val_loss: 49.0892\n",
      "Epoch 141/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8868 - val_loss: 48.5393\n",
      "Epoch 142/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8126 - val_loss: 50.4980\n",
      "Epoch 143/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0873 - val_loss: 49.7609\n",
      "Epoch 144/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0470 - val_loss: 48.8165\n",
      "Epoch 145/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8289 - val_loss: 48.5318\n",
      "Epoch 146/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8824 - val_loss: 48.8470\n",
      "Epoch 147/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3863 - val_loss: 50.0659\n",
      "Epoch 148/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9188 - val_loss: 49.1273\n",
      "Epoch 149/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0791 - val_loss: 50.3773\n",
      "Epoch 150/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8413 - val_loss: 50.2269\n",
      "Epoch 151/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9796 - val_loss: 50.1322\n",
      "Epoch 152/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1927 - val_loss: 49.1852\n",
      "Epoch 153/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9779 - val_loss: 49.4866\n",
      "Epoch 154/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9151 - val_loss: 49.6115\n",
      "Epoch 155/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9654 - val_loss: 48.6449\n",
      "Epoch 156/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7727 - val_loss: 48.8212\n",
      "Epoch 157/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7519 - val_loss: 48.5944\n",
      "Epoch 158/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7863 - val_loss: 48.6840\n",
      "Epoch 159/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6632 - val_loss: 49.4475\n",
      "Epoch 160/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7815 - val_loss: 49.0401\n",
      "Epoch 161/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9177 - val_loss: 48.9024\n",
      "Epoch 162/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5489 - val_loss: 49.1914\n",
      "Epoch 163/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0907 - val_loss: 48.9613\n",
      "Epoch 164/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8531 - val_loss: 49.1791\n",
      "Epoch 165/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6946 - val_loss: 59.4980\n",
      "Epoch 166/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8514 - val_loss: 48.1553\n",
      "Epoch 167/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8731 - val_loss: 49.2307\n",
      "Epoch 168/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7384 - val_loss: 51.0368\n",
      "Epoch 169/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8807 - val_loss: 49.5578\n",
      "Epoch 170/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5371 - val_loss: 48.5177\n",
      "Epoch 171/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7960 - val_loss: 49.6090\n",
      "Epoch 172/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6981 - val_loss: 51.8651\n",
      "Epoch 173/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7164 - val_loss: 50.2531\n",
      "Epoch 174/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3213 - val_loss: 48.4427\n",
      "Epoch 175/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2716 - val_loss: 49.3242\n",
      "Epoch 176/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4037 - val_loss: 48.7263\n",
      "Epoch 177/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5592 - val_loss: 49.2180\n",
      "Epoch 178/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8673 - val_loss: 48.5809\n",
      "Epoch 179/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6306 - val_loss: 48.3762\n",
      "Epoch 180/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7511 - val_loss: 48.7951\n",
      "Epoch 181/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8820 - val_loss: 48.2310\n",
      "Epoch 182/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6638 - val_loss: 50.2122\n",
      "Epoch 183/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4569 - val_loss: 49.9303\n",
      "Epoch 184/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7263 - val_loss: 48.3749\n",
      "Epoch 185/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4087 - val_loss: 48.5201\n",
      "Epoch 186/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4567 - val_loss: 49.3157\n",
      "Epoch 187/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7933 - val_loss: 49.0095\n",
      "Epoch 188/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5791 - val_loss: 48.1849\n",
      "Epoch 189/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7688 - val_loss: 51.3647\n",
      "Epoch 190/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4602 - val_loss: 48.1473\n",
      "Epoch 191/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8414 - val_loss: 48.9017\n",
      "Epoch 192/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5408 - val_loss: 48.7192\n",
      "Epoch 193/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5231 - val_loss: 49.1191\n",
      "Epoch 194/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3119 - val_loss: 49.4442\n",
      "Epoch 195/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5275 - val_loss: 49.3281\n",
      "Epoch 196/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5381 - val_loss: 49.9807\n",
      "Epoch 197/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2438 - val_loss: 49.3254\n",
      "Epoch 198/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2939 - val_loss: 48.2071\n",
      "Epoch 199/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5602 - val_loss: 49.6862\n",
      "Epoch 200/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5939 - val_loss: 49.8469\n",
      "Epoch 201/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2863 - val_loss: 48.6292\n",
      "Epoch 202/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6135 - val_loss: 49.1934\n",
      "Epoch 203/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4613 - val_loss: 48.2903\n",
      "Epoch 204/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4710 - val_loss: 50.6068\n",
      "Epoch 205/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3392 - val_loss: 48.3275\n",
      "Epoch 206/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2045 - val_loss: 48.3813\n",
      "Epoch 207/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6447 - val_loss: 48.6004\n",
      "Epoch 208/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4705 - val_loss: 49.7472\n",
      "Epoch 209/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2940 - val_loss: 48.2297\n",
      "Epoch 210/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1478 - val_loss: 48.2219\n",
      "Epoch 211/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3992 - val_loss: 49.3331\n",
      "Epoch 212/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1694 - val_loss: 48.1357\n",
      "Epoch 213/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2177 - val_loss: 48.0817\n",
      "Epoch 214/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5954 - val_loss: 49.4716\n",
      "Epoch 215/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1177 - val_loss: 48.2862\n",
      "Epoch 216/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2353 - val_loss: 48.0271\n",
      "Epoch 217/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1385 - val_loss: 48.3510\n",
      "Epoch 218/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2827 - val_loss: 48.0184\n",
      "Epoch 219/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0825 - val_loss: 51.0280\n",
      "Epoch 220/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4323 - val_loss: 49.1325\n",
      "Epoch 221/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4902 - val_loss: 49.3625\n",
      "Epoch 222/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2290 - val_loss: 47.8137\n",
      "Epoch 223/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3082 - val_loss: 51.8498\n",
      "Epoch 224/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4379 - val_loss: 48.5679\n",
      "Epoch 225/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5677 - val_loss: 50.4647\n",
      "Epoch 226/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3433 - val_loss: 48.2917\n",
      "Epoch 227/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3597 - val_loss: 51.5811\n",
      "Epoch 228/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0255 - val_loss: 48.5273\n",
      "Epoch 229/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2646 - val_loss: 48.2947\n",
      "Epoch 230/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4670 - val_loss: 47.8583\n",
      "Epoch 231/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1115 - val_loss: 48.3055\n",
      "Epoch 232/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0577 - val_loss: 48.5879\n",
      "Epoch 233/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2107 - val_loss: 49.2072\n",
      "Epoch 234/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5888 - val_loss: 48.0491\n",
      "Epoch 235/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0400 - val_loss: 52.2307\n",
      "Epoch 236/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4054 - val_loss: 48.4991\n",
      "Epoch 237/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2929 - val_loss: 48.1369\n",
      "Epoch 238/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1929 - val_loss: 48.0856\n",
      "Epoch 239/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0759 - val_loss: 48.1223\n",
      "Epoch 240/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1479 - val_loss: 48.7796\n",
      "Epoch 241/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0551 - val_loss: 49.0529\n",
      "Epoch 242/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9920 - val_loss: 49.4037\n",
      "Epoch 243/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8776 - val_loss: 47.7396\n",
      "Epoch 244/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2075 - val_loss: 47.9563\n",
      "Epoch 245/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9731 - val_loss: 47.9417\n",
      "Epoch 246/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2842 - val_loss: 48.4792\n",
      "Epoch 247/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3047 - val_loss: 48.4276\n",
      "Epoch 248/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0338 - val_loss: 59.0590\n",
      "Epoch 249/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4692 - val_loss: 50.1943\n",
      "Epoch 250/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1600 - val_loss: 48.9408\n",
      "Epoch 251/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2354 - val_loss: 48.0659\n",
      "Epoch 252/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9928 - val_loss: 49.4671\n",
      "Epoch 253/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2441 - val_loss: 48.0375\n",
      "Epoch 254/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9198 - val_loss: 48.1272\n",
      "Epoch 255/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1483 - val_loss: 47.8279\n",
      "Epoch 256/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1528 - val_loss: 47.8772\n",
      "Epoch 257/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9296 - val_loss: 47.8246\n",
      "Epoch 258/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0386 - val_loss: 48.1677\n",
      "Epoch 259/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2178 - val_loss: 48.8568\n",
      "Epoch 260/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8664 - val_loss: 47.9386\n",
      "Epoch 261/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1952 - val_loss: 48.2856\n",
      "Epoch 262/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 47.9045 - val_loss: 50.0384\n",
      "Epoch 263/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1604 - val_loss: 47.7684\n",
      "Epoch 264/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3426 - val_loss: 48.7007\n",
      "Epoch 265/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 48.4565 - val_loss: 48.1235\n",
      "Epoch 266/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8027 - val_loss: 48.2412\n",
      "Epoch 267/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1160 - val_loss: 48.1122\n",
      "Epoch 268/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 48.0396 - val_loss: 48.1693\n",
      "Epoch 269/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0128 - val_loss: 48.9290\n",
      "Epoch 270/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9337 - val_loss: 48.0871\n",
      "Epoch 271/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 47.8204 - val_loss: 49.6470\n",
      "Epoch 272/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9048 - val_loss: 48.6930\n",
      "Epoch 273/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9184 - val_loss: 47.9358\n",
      "Epoch 274/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6433 - val_loss: 47.6325\n",
      "Epoch 275/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8111 - val_loss: 48.4696\n",
      "Epoch 276/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9817 - val_loss: 48.2941\n",
      "Epoch 277/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0047 - val_loss: 47.8824\n",
      "Epoch 278/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9749 - val_loss: 48.5248\n",
      "Epoch 279/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6834 - val_loss: 49.6548\n",
      "Epoch 280/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0416 - val_loss: 47.8176\n",
      "Epoch 281/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8780 - val_loss: 51.3792\n",
      "Epoch 282/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0363 - val_loss: 48.8592\n",
      "Epoch 283/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8989 - val_loss: 49.0941\n",
      "Epoch 284/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7225 - val_loss: 48.7940\n",
      "Epoch 285/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9922 - val_loss: 53.9179\n",
      "Epoch 286/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1787 - val_loss: 50.0149\n",
      "Epoch 287/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6343 - val_loss: 50.2658\n",
      "Epoch 288/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7222 - val_loss: 53.8161\n",
      "Epoch 289/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0085 - val_loss: 48.9709\n",
      "Epoch 290/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5882 - val_loss: 47.9478\n",
      "Epoch 291/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7777 - val_loss: 50.6820\n",
      "Epoch 292/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8317 - val_loss: 48.4570\n",
      "Epoch 293/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9253 - val_loss: 52.5793\n",
      "Epoch 294/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 47.5773 - val_loss: 48.6259\n",
      "Epoch 295/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8099 - val_loss: 48.4529\n",
      "Epoch 296/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6821 - val_loss: 50.9416\n",
      "Epoch 297/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0373 - val_loss: 47.6368\n",
      "Epoch 298/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8068 - val_loss: 47.9510\n",
      "Epoch 299/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1936 - val_loss: 47.8018\n",
      "Epoch 300/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8622 - val_loss: 47.7266\n",
      "Epoch 301/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0097 - val_loss: 47.7814\n",
      "Epoch 302/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6928 - val_loss: 48.3158\n",
      "Epoch 303/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9461 - val_loss: 47.5448\n",
      "Epoch 304/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6048 - val_loss: 47.9389\n",
      "Epoch 305/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8967 - val_loss: 50.8230\n",
      "Epoch 306/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9988 - val_loss: 48.9830\n",
      "Epoch 307/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7836 - val_loss: 48.2280\n",
      "Epoch 308/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0313 - val_loss: 49.2576\n",
      "Epoch 309/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6056 - val_loss: 48.0796\n",
      "Epoch 310/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5985 - val_loss: 47.7725\n",
      "Epoch 311/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6743 - val_loss: 48.2170\n",
      "Epoch 312/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8632 - val_loss: 48.3578\n",
      "Epoch 313/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8366 - val_loss: 48.1420\n",
      "Epoch 314/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8939 - val_loss: 47.7030\n",
      "Epoch 315/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5707 - val_loss: 49.0803\n",
      "Epoch 316/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7734 - val_loss: 47.8028\n",
      "Epoch 317/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6644 - val_loss: 48.5853\n",
      "Epoch 318/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9953 - val_loss: 49.1195\n",
      "Epoch 319/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0441 - val_loss: 48.5319\n",
      "Epoch 320/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6943 - val_loss: 48.4357\n",
      "Epoch 321/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 47.8886 - val_loss: 48.3158\n",
      "Epoch 322/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8412 - val_loss: 48.2264\n",
      "Epoch 323/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6596 - val_loss: 48.7851\n",
      "Epoch 324/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7273 - val_loss: 47.7947\n",
      "Epoch 325/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6007 - val_loss: 47.8039\n",
      "Epoch 326/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3670 - val_loss: 47.9784\n",
      "Epoch 327/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4471 - val_loss: 52.3987\n",
      "Epoch 328/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7150 - val_loss: 47.5821\n",
      "Epoch 329/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8365 - val_loss: 51.1288\n",
      "Epoch 330/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0037 - val_loss: 48.6249\n",
      "Epoch 331/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6001 - val_loss: 47.7797\n",
      "Epoch 332/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7299 - val_loss: 49.1025\n",
      "Epoch 333/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6489 - val_loss: 47.6275\n",
      "Epoch 334/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7097 - val_loss: 47.8642\n",
      "Epoch 335/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1833 - val_loss: 50.7106\n",
      "Epoch 336/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7454 - val_loss: 49.0309\n",
      "Epoch 337/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5567 - val_loss: 49.0938\n",
      "Epoch 338/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4549 - val_loss: 47.4354\n",
      "Epoch 339/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8988 - val_loss: 47.8670\n",
      "Epoch 340/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5863 - val_loss: 47.8452\n",
      "Epoch 341/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6595 - val_loss: 47.8262\n",
      "Epoch 342/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3424 - val_loss: 47.4725\n",
      "Epoch 343/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7341 - val_loss: 47.4938\n",
      "Epoch 344/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5073 - val_loss: 50.3491\n",
      "Epoch 345/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3620 - val_loss: 47.8381\n",
      "Epoch 346/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7019 - val_loss: 47.7941\n",
      "Epoch 347/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8057 - val_loss: 48.4822\n",
      "Epoch 348/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6356 - val_loss: 47.4735\n",
      "Epoch 349/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5776 - val_loss: 48.5109\n",
      "Epoch 350/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4277 - val_loss: 47.9379\n",
      "Epoch 351/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7668 - val_loss: 48.1001\n",
      "Epoch 352/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6636 - val_loss: 47.4139\n",
      "Epoch 353/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5924 - val_loss: 52.9813\n",
      "Epoch 354/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7252 - val_loss: 48.5596\n",
      "Epoch 355/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5745 - val_loss: 48.4586\n",
      "Epoch 356/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3604 - val_loss: 47.5489\n",
      "Epoch 357/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5867 - val_loss: 47.8473\n",
      "Epoch 358/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4672 - val_loss: 48.0715\n",
      "Epoch 359/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6086 - val_loss: 48.2335\n",
      "Epoch 360/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7967 - val_loss: 47.8568\n",
      "Epoch 361/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9321 - val_loss: 47.5428\n",
      "Epoch 362/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4143 - val_loss: 47.4163\n",
      "Epoch 363/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4171 - val_loss: 47.9424\n",
      "Epoch 364/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.0999 - val_loss: 48.1851\n",
      "Epoch 365/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3620 - val_loss: 48.5954\n",
      "Epoch 366/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3192 - val_loss: 48.1032\n",
      "Epoch 367/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5157 - val_loss: 47.3119\n",
      "Epoch 368/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5573 - val_loss: 48.3398\n",
      "Epoch 369/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3778 - val_loss: 48.2530\n",
      "Epoch 370/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3519 - val_loss: 47.4885\n",
      "Epoch 371/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.6712 - val_loss: 49.0196\n",
      "Epoch 372/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7420 - val_loss: 49.5360\n",
      "Epoch 373/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6882 - val_loss: 48.7280\n",
      "Epoch 374/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4507 - val_loss: 47.8856\n",
      "Epoch 375/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.2385 - val_loss: 48.2057\n",
      "Epoch 376/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5792 - val_loss: 48.5113\n",
      "Epoch 377/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4444 - val_loss: 49.1154\n",
      "Epoch 378/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3201 - val_loss: 48.2795\n",
      "Epoch 379/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.1725 - val_loss: 49.1961\n",
      "Epoch 380/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4806 - val_loss: 47.4534\n",
      "Epoch 381/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3451 - val_loss: 48.5848\n",
      "Epoch 382/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4904 - val_loss: 50.5733\n",
      "Epoch 383/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5487 - val_loss: 50.4670\n",
      "Epoch 384/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6648 - val_loss: 48.4020\n",
      "Epoch 385/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4872 - val_loss: 49.0966\n",
      "Epoch 386/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7380 - val_loss: 47.6757\n",
      "Epoch 387/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3965 - val_loss: 47.3828\n",
      "Epoch 388/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7037 - val_loss: 48.0284\n",
      "Epoch 389/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.3363 - val_loss: 49.9394\n",
      "Epoch 390/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.2798 - val_loss: 47.6215\n",
      "Epoch 391/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 47.3414 - val_loss: 49.7756\n",
      "Epoch 392/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3631 - val_loss: 48.4142\n",
      "Epoch 393/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5469 - val_loss: 47.4866\n",
      "Epoch 394/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3558 - val_loss: 47.7605\n",
      "Epoch 395/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6639 - val_loss: 51.2729\n",
      "Epoch 396/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3394 - val_loss: 48.4115\n",
      "Epoch 397/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5493 - val_loss: 51.5093\n",
      "Epoch 398/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 47.2902 - val_loss: 47.8316\n",
      "Epoch 399/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5333 - val_loss: 47.9048\n",
      "Epoch 400/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6915 - val_loss: 47.3367\n",
      "Epoch 401/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7230 - val_loss: 51.0915\n",
      "Epoch 402/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3840 - val_loss: 47.5373\n",
      "Epoch 403/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6735 - val_loss: 48.5967\n",
      "Epoch 404/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5011 - val_loss: 47.5452\n",
      "Epoch 405/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4184 - val_loss: 49.3531\n",
      "Epoch 406/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 47.0763 - val_loss: 48.2511\n",
      "Epoch 407/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4629 - val_loss: 47.5340\n",
      "Epoch 408/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.2319 - val_loss: 47.4839\n",
      "Epoch 409/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5264 - val_loss: 47.7653\n",
      "Epoch 410/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.1972 - val_loss: 47.6101\n",
      "Epoch 411/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3188 - val_loss: 48.4058\n",
      "Epoch 412/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5065 - val_loss: 48.0631\n",
      "Epoch 413/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.1549 - val_loss: 47.4916\n",
      "Epoch 414/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4052 - val_loss: 52.3172\n",
      "Epoch 415/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3818 - val_loss: 49.2465\n",
      "Epoch 416/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4153 - val_loss: 47.8279\n",
      "Epoch 417/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7031 - val_loss: 48.0961\n",
      "216/216 [==============================] - 0s 2ms/step\n",
      "861/861 [==============================] - 1s 1ms/step\n",
      "Fold 2\n",
      "Epoch 1/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 59.9590 - val_loss: 53.4644\n",
      "Epoch 2/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 53.4831 - val_loss: 50.8602\n",
      "Epoch 3/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 53.4683 - val_loss: 50.5700\n",
      "Epoch 4/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 53.0344 - val_loss: 50.6867\n",
      "Epoch 5/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 53.1453 - val_loss: 50.7413\n",
      "Epoch 6/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 53.2884 - val_loss: 50.7428\n",
      "Epoch 7/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.7281 - val_loss: 50.9012\n",
      "Epoch 8/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.6372 - val_loss: 51.1015\n",
      "Epoch 9/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.7730 - val_loss: 50.7930\n",
      "Epoch 10/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.6849 - val_loss: 51.4597\n",
      "Epoch 11/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.2675 - val_loss: 52.8894\n",
      "Epoch 12/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.5024 - val_loss: 50.5039\n",
      "Epoch 13/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.5122 - val_loss: 50.3035\n",
      "Epoch 14/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.0798 - val_loss: 50.3129\n",
      "Epoch 15/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.3777 - val_loss: 51.3438\n",
      "Epoch 16/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.1365 - val_loss: 52.5422\n",
      "Epoch 17/10000\n",
      "646/646 [==============================] - 3s 4ms/step - loss: 52.0130 - val_loss: 50.4876\n",
      "Epoch 18/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.1451 - val_loss: 50.1992\n",
      "Epoch 19/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.1716 - val_loss: 50.1639\n",
      "Epoch 20/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.2253 - val_loss: 50.4736\n",
      "Epoch 21/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.0079 - val_loss: 52.0345\n",
      "Epoch 22/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.9224 - val_loss: 50.2751\n",
      "Epoch 23/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.8319 - val_loss: 50.1401\n",
      "Epoch 24/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.1969 - val_loss: 50.4072\n",
      "Epoch 25/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.8177 - val_loss: 50.3709\n",
      "Epoch 26/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.3396 - val_loss: 53.3697\n",
      "Epoch 27/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.9720 - val_loss: 51.5051\n",
      "Epoch 28/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.7507 - val_loss: 51.2467\n",
      "Epoch 29/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.7098 - val_loss: 50.5777\n",
      "Epoch 30/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.8832 - val_loss: 50.5285\n",
      "Epoch 31/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.7981 - val_loss: 50.9665\n",
      "Epoch 32/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.9355 - val_loss: 51.2493\n",
      "Epoch 33/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.7428 - val_loss: 52.4496\n",
      "Epoch 34/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.9090 - val_loss: 50.7269\n",
      "Epoch 35/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.6672 - val_loss: 50.7927\n",
      "Epoch 36/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.9205 - val_loss: 50.4540\n",
      "Epoch 37/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6745 - val_loss: 50.8070\n",
      "Epoch 38/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.7161 - val_loss: 50.2526\n",
      "Epoch 39/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.8351 - val_loss: 50.3252\n",
      "Epoch 40/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.7277 - val_loss: 50.0638\n",
      "Epoch 41/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6153 - val_loss: 50.3922\n",
      "Epoch 42/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6883 - val_loss: 50.7342\n",
      "Epoch 43/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.6544 - val_loss: 50.2789\n",
      "Epoch 44/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5497 - val_loss: 50.2204\n",
      "Epoch 45/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.8488 - val_loss: 50.2416\n",
      "Epoch 46/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6049 - val_loss: 49.8925\n",
      "Epoch 47/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4985 - val_loss: 50.2378\n",
      "Epoch 48/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.7128 - val_loss: 50.6080\n",
      "Epoch 49/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4764 - val_loss: 50.4005\n",
      "Epoch 50/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5410 - val_loss: 49.9669\n",
      "Epoch 51/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5146 - val_loss: 52.4185\n",
      "Epoch 52/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4134 - val_loss: 50.3069\n",
      "Epoch 53/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4231 - val_loss: 50.0497\n",
      "Epoch 54/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5015 - val_loss: 50.0854\n",
      "Epoch 55/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3162 - val_loss: 50.6702\n",
      "Epoch 56/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6158 - val_loss: 50.0076\n",
      "Epoch 57/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3925 - val_loss: 49.9757\n",
      "Epoch 58/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6818 - val_loss: 50.0191\n",
      "Epoch 59/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4093 - val_loss: 49.9213\n",
      "Epoch 60/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4848 - val_loss: 50.2306\n",
      "Epoch 61/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4876 - val_loss: 50.0930\n",
      "Epoch 62/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5248 - val_loss: 54.3224\n",
      "Epoch 63/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.2624 - val_loss: 50.0092\n",
      "Epoch 64/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4599 - val_loss: 49.9692\n",
      "Epoch 65/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3415 - val_loss: 49.7980\n",
      "Epoch 66/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6057 - val_loss: 49.9542\n",
      "Epoch 67/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1902 - val_loss: 49.7502\n",
      "Epoch 68/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1711 - val_loss: 51.8624\n",
      "Epoch 69/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1945 - val_loss: 49.9715\n",
      "Epoch 70/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.2670 - val_loss: 50.4089\n",
      "Epoch 71/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1790 - val_loss: 49.8735\n",
      "Epoch 72/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3381 - val_loss: 49.7553\n",
      "Epoch 73/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9841 - val_loss: 49.7603\n",
      "Epoch 74/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3009 - val_loss: 49.6515\n",
      "Epoch 75/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9385 - val_loss: 49.7354\n",
      "Epoch 76/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0358 - val_loss: 50.7836\n",
      "Epoch 77/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1650 - val_loss: 50.0228\n",
      "Epoch 78/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1098 - val_loss: 49.7803\n",
      "Epoch 79/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9617 - val_loss: 50.0605\n",
      "Epoch 80/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9231 - val_loss: 49.0220\n",
      "Epoch 81/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.8425 - val_loss: 49.4121\n",
      "Epoch 82/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.9439 - val_loss: 49.4634\n",
      "Epoch 83/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.6893 - val_loss: 49.4917\n",
      "Epoch 84/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.8444 - val_loss: 52.8689\n",
      "Epoch 85/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9229 - val_loss: 49.0411\n",
      "Epoch 86/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.8268 - val_loss: 52.9399\n",
      "Epoch 87/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.4216 - val_loss: 48.5595\n",
      "Epoch 88/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.5794 - val_loss: 49.9221\n",
      "Epoch 89/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.7486 - val_loss: 48.6375\n",
      "Epoch 90/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.5565 - val_loss: 49.2449\n",
      "Epoch 91/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.5413 - val_loss: 49.1559\n",
      "Epoch 92/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.7714 - val_loss: 48.6071\n",
      "Epoch 93/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.5976 - val_loss: 52.7321\n",
      "Epoch 94/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.5577 - val_loss: 49.5506\n",
      "Epoch 95/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.3890 - val_loss: 49.6857\n",
      "Epoch 96/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.2839 - val_loss: 48.8240\n",
      "Epoch 97/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.4367 - val_loss: 48.3921\n",
      "Epoch 98/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.2982 - val_loss: 50.9370\n",
      "Epoch 99/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.6689 - val_loss: 49.6096\n",
      "Epoch 100/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.2722 - val_loss: 49.1106\n",
      "Epoch 101/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.4335 - val_loss: 48.8587\n",
      "Epoch 102/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0318 - val_loss: 48.8093\n",
      "Epoch 103/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.1375 - val_loss: 49.8794\n",
      "Epoch 104/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.2013 - val_loss: 48.7037\n",
      "Epoch 105/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0440 - val_loss: 49.5123\n",
      "Epoch 106/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0598 - val_loss: 47.8659\n",
      "Epoch 107/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.3876 - val_loss: 49.3686\n",
      "Epoch 108/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.8048 - val_loss: 48.4359\n",
      "Epoch 109/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.9782 - val_loss: 50.3147\n",
      "Epoch 110/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6990 - val_loss: 51.9449\n",
      "Epoch 111/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0582 - val_loss: 48.1163\n",
      "Epoch 112/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.7329 - val_loss: 47.4159\n",
      "Epoch 113/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.7238 - val_loss: 50.2651\n",
      "Epoch 114/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.7029 - val_loss: 47.7637\n",
      "Epoch 115/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.7708 - val_loss: 48.0478\n",
      "Epoch 116/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5876 - val_loss: 48.0558\n",
      "Epoch 117/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.8360 - val_loss: 48.0395\n",
      "Epoch 118/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.7068 - val_loss: 48.7732\n",
      "Epoch 119/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.0079 - val_loss: 48.3521\n",
      "Epoch 120/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5692 - val_loss: 47.8839\n",
      "Epoch 121/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6110 - val_loss: 47.5790\n",
      "Epoch 122/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5129 - val_loss: 47.8956\n",
      "Epoch 123/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.7051 - val_loss: 48.8926\n",
      "Epoch 124/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.2378 - val_loss: 49.2395\n",
      "Epoch 125/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 49.5950 - val_loss: 48.0336\n",
      "Epoch 126/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6146 - val_loss: 50.0658\n",
      "Epoch 127/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5382 - val_loss: 47.6732\n",
      "Epoch 128/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4802 - val_loss: 47.9834\n",
      "Epoch 129/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4936 - val_loss: 47.8894\n",
      "Epoch 130/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3211 - val_loss: 48.6935\n",
      "Epoch 131/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3512 - val_loss: 47.8831\n",
      "Epoch 132/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4318 - val_loss: 47.7259\n",
      "Epoch 133/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4562 - val_loss: 50.4115\n",
      "Epoch 134/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5362 - val_loss: 47.2631\n",
      "Epoch 135/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3469 - val_loss: 47.7855\n",
      "Epoch 136/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6049 - val_loss: 48.0684\n",
      "Epoch 137/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4343 - val_loss: 52.8575\n",
      "Epoch 138/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 49.5738 - val_loss: 48.2392\n",
      "Epoch 139/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 49.5460 - val_loss: 48.5402\n",
      "Epoch 140/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6713 - val_loss: 47.6171\n",
      "Epoch 141/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3986 - val_loss: 49.1286\n",
      "Epoch 142/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2058 - val_loss: 50.9339\n",
      "Epoch 143/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3250 - val_loss: 47.5342\n",
      "Epoch 144/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6570 - val_loss: 48.2393\n",
      "Epoch 145/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1742 - val_loss: 48.2400\n",
      "Epoch 146/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4326 - val_loss: 50.3772\n",
      "Epoch 147/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4223 - val_loss: 48.4173\n",
      "Epoch 148/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3138 - val_loss: 48.2262\n",
      "Epoch 149/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0857 - val_loss: 47.6501\n",
      "Epoch 150/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0909 - val_loss: 48.3697\n",
      "Epoch 151/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4435 - val_loss: 50.0969\n",
      "Epoch 152/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2098 - val_loss: 47.5986\n",
      "Epoch 153/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0853 - val_loss: 47.8649\n",
      "Epoch 154/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1892 - val_loss: 48.2649\n",
      "Epoch 155/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4417 - val_loss: 47.5096\n",
      "Epoch 156/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2595 - val_loss: 47.7033\n",
      "Epoch 157/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5810 - val_loss: 49.7868\n",
      "Epoch 158/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3185 - val_loss: 49.8244\n",
      "Epoch 159/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3571 - val_loss: 48.0901\n",
      "Epoch 160/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8860 - val_loss: 52.1137\n",
      "Epoch 161/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3500 - val_loss: 50.0586\n",
      "Epoch 162/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2386 - val_loss: 49.2808\n",
      "Epoch 163/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3413 - val_loss: 48.4451\n",
      "Epoch 164/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9645 - val_loss: 51.7770\n",
      "Epoch 165/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1485 - val_loss: 47.9479\n",
      "Epoch 166/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3609 - val_loss: 47.2094\n",
      "Epoch 167/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0745 - val_loss: 49.6407\n",
      "Epoch 168/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8318 - val_loss: 47.2595\n",
      "Epoch 169/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0485 - val_loss: 47.1164\n",
      "Epoch 170/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9255 - val_loss: 47.0502\n",
      "Epoch 171/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0585 - val_loss: 48.0483\n",
      "Epoch 172/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0464 - val_loss: 47.0597\n",
      "Epoch 173/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9781 - val_loss: 47.5032\n",
      "Epoch 174/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.9873 - val_loss: 48.7787\n",
      "Epoch 175/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.0754 - val_loss: 48.3715\n",
      "Epoch 176/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0157 - val_loss: 47.5623\n",
      "Epoch 177/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.9835 - val_loss: 46.8538\n",
      "Epoch 178/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8183 - val_loss: 50.1358\n",
      "Epoch 179/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9324 - val_loss: 46.8847\n",
      "Epoch 180/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8881 - val_loss: 48.2966\n",
      "Epoch 181/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9002 - val_loss: 47.3782\n",
      "Epoch 182/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2827 - val_loss: 47.0314\n",
      "Epoch 183/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9584 - val_loss: 47.4820\n",
      "Epoch 184/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9506 - val_loss: 48.8324\n",
      "Epoch 185/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.8291 - val_loss: 49.5849\n",
      "Epoch 186/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1078 - val_loss: 47.7855\n",
      "Epoch 187/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0771 - val_loss: 49.5523\n",
      "Epoch 188/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 49.1711 - val_loss: 47.4611\n",
      "Epoch 189/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.8810 - val_loss: 47.2978\n",
      "Epoch 190/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0909 - val_loss: 48.9305\n",
      "Epoch 191/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6187 - val_loss: 47.2691\n",
      "Epoch 192/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.9354 - val_loss: 51.1053\n",
      "Epoch 193/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7589 - val_loss: 47.1192\n",
      "Epoch 194/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7976 - val_loss: 48.2987\n",
      "Epoch 195/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.5766 - val_loss: 47.0245\n",
      "Epoch 196/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6119 - val_loss: 47.3277\n",
      "Epoch 197/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8262 - val_loss: 50.6090\n",
      "Epoch 198/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0613 - val_loss: 46.6908\n",
      "Epoch 199/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.8642 - val_loss: 47.9765\n",
      "Epoch 200/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8484 - val_loss: 47.4355\n",
      "Epoch 201/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6645 - val_loss: 46.9637\n",
      "Epoch 202/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.9841 - val_loss: 48.7354\n",
      "Epoch 203/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5027 - val_loss: 51.1916\n",
      "Epoch 204/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7583 - val_loss: 50.0103\n",
      "Epoch 205/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9597 - val_loss: 47.2813\n",
      "Epoch 206/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6859 - val_loss: 47.5477\n",
      "Epoch 207/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9464 - val_loss: 48.6892\n",
      "Epoch 208/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8450 - val_loss: 47.6220\n",
      "Epoch 209/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4900 - val_loss: 47.5709\n",
      "Epoch 210/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6639 - val_loss: 47.1198\n",
      "Epoch 211/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6300 - val_loss: 50.2749\n",
      "Epoch 212/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6912 - val_loss: 47.3380\n",
      "Epoch 213/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7728 - val_loss: 47.6764\n",
      "Epoch 214/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6754 - val_loss: 48.8126\n",
      "Epoch 215/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6430 - val_loss: 49.8170\n",
      "Epoch 216/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5260 - val_loss: 47.0477\n",
      "Epoch 217/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6302 - val_loss: 47.1383\n",
      "Epoch 218/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7050 - val_loss: 47.1004\n",
      "Epoch 219/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8575 - val_loss: 47.4569\n",
      "Epoch 220/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4679 - val_loss: 47.1382\n",
      "Epoch 221/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4684 - val_loss: 47.2436\n",
      "Epoch 222/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4663 - val_loss: 47.4642\n",
      "Epoch 223/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5627 - val_loss: 48.1871\n",
      "Epoch 224/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5753 - val_loss: 48.5318\n",
      "Epoch 225/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7373 - val_loss: 48.2997\n",
      "Epoch 226/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5845 - val_loss: 47.0245\n",
      "Epoch 227/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5433 - val_loss: 48.5574\n",
      "Epoch 228/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.9281 - val_loss: 46.9284\n",
      "Epoch 229/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6615 - val_loss: 47.2295\n",
      "Epoch 230/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4124 - val_loss: 46.8009\n",
      "Epoch 231/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4816 - val_loss: 51.0946\n",
      "Epoch 232/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3820 - val_loss: 46.5742\n",
      "Epoch 233/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4353 - val_loss: 48.2197\n",
      "Epoch 234/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9311 - val_loss: 49.1870\n",
      "Epoch 235/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5835 - val_loss: 47.6521\n",
      "Epoch 236/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6834 - val_loss: 48.8398\n",
      "Epoch 237/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6446 - val_loss: 47.1364\n",
      "Epoch 238/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6580 - val_loss: 47.1388\n",
      "Epoch 239/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3649 - val_loss: 47.4644\n",
      "Epoch 240/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7567 - val_loss: 47.6272\n",
      "Epoch 241/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5423 - val_loss: 47.3563\n",
      "Epoch 242/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4923 - val_loss: 47.4811\n",
      "Epoch 243/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7721 - val_loss: 47.9333\n",
      "Epoch 244/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4285 - val_loss: 47.1664\n",
      "Epoch 245/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7607 - val_loss: 48.9400\n",
      "Epoch 246/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5784 - val_loss: 46.5687\n",
      "Epoch 247/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3562 - val_loss: 50.9501\n",
      "Epoch 248/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6007 - val_loss: 46.5097\n",
      "Epoch 249/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3962 - val_loss: 48.5138\n",
      "Epoch 250/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3659 - val_loss: 47.6441\n",
      "Epoch 251/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.3859 - val_loss: 46.8796\n",
      "Epoch 252/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6264 - val_loss: 47.1477\n",
      "Epoch 253/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5849 - val_loss: 47.0886\n",
      "Epoch 254/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4764 - val_loss: 47.1821\n",
      "Epoch 255/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2630 - val_loss: 46.8760\n",
      "Epoch 256/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5534 - val_loss: 47.4258\n",
      "Epoch 257/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4832 - val_loss: 47.3070\n",
      "Epoch 258/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2214 - val_loss: 50.4230\n",
      "Epoch 259/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3211 - val_loss: 46.4825\n",
      "Epoch 260/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4003 - val_loss: 46.9257\n",
      "Epoch 261/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5953 - val_loss: 53.0435\n",
      "Epoch 262/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6393 - val_loss: 46.9301\n",
      "Epoch 263/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5414 - val_loss: 46.6718\n",
      "Epoch 264/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3769 - val_loss: 46.5925\n",
      "Epoch 265/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4610 - val_loss: 50.3469\n",
      "Epoch 266/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3422 - val_loss: 46.9703\n",
      "Epoch 267/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2911 - val_loss: 49.2019\n",
      "Epoch 268/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4094 - val_loss: 48.8409\n",
      "Epoch 269/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4186 - val_loss: 47.6023\n",
      "Epoch 270/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3713 - val_loss: 47.0673\n",
      "Epoch 271/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4186 - val_loss: 47.1825\n",
      "Epoch 272/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4575 - val_loss: 46.5048\n",
      "Epoch 273/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3299 - val_loss: 46.4034\n",
      "Epoch 274/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2841 - val_loss: 46.8538\n",
      "Epoch 275/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3525 - val_loss: 47.1430\n",
      "Epoch 276/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4475 - val_loss: 46.7511\n",
      "Epoch 277/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4480 - val_loss: 46.4677\n",
      "Epoch 278/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1979 - val_loss: 48.2244\n",
      "Epoch 279/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5203 - val_loss: 46.7697\n",
      "Epoch 280/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1903 - val_loss: 46.4044\n",
      "Epoch 281/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2818 - val_loss: 46.5661\n",
      "Epoch 282/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2820 - val_loss: 46.5800\n",
      "Epoch 283/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3518 - val_loss: 50.0670\n",
      "Epoch 284/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2019 - val_loss: 48.6370\n",
      "Epoch 285/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3119 - val_loss: 46.7146\n",
      "Epoch 286/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9896 - val_loss: 47.8913\n",
      "Epoch 287/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1806 - val_loss: 47.0824\n",
      "Epoch 288/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3957 - val_loss: 46.4671\n",
      "Epoch 289/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2279 - val_loss: 46.5910\n",
      "Epoch 290/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9945 - val_loss: 49.6049\n",
      "Epoch 291/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2476 - val_loss: 48.3010\n",
      "Epoch 292/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4183 - val_loss: 47.3675\n",
      "Epoch 293/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2008 - val_loss: 47.0193\n",
      "Epoch 294/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3112 - val_loss: 47.7458\n",
      "Epoch 295/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2859 - val_loss: 47.3167\n",
      "Epoch 296/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2820 - val_loss: 48.2965\n",
      "Epoch 297/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3799 - val_loss: 47.6040\n",
      "Epoch 298/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2803 - val_loss: 48.8933\n",
      "Epoch 299/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0892 - val_loss: 46.5568\n",
      "Epoch 300/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2862 - val_loss: 46.8767\n",
      "Epoch 301/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1014 - val_loss: 46.4200\n",
      "Epoch 302/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2199 - val_loss: 46.8069\n",
      "Epoch 303/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1251 - val_loss: 47.3409\n",
      "Epoch 304/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9764 - val_loss: 46.3679\n",
      "Epoch 305/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0526 - val_loss: 47.0507\n",
      "Epoch 306/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0405 - val_loss: 46.3147\n",
      "Epoch 307/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3037 - val_loss: 47.0194\n",
      "Epoch 308/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1641 - val_loss: 48.2245\n",
      "Epoch 309/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0608 - val_loss: 47.1978\n",
      "Epoch 310/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3692 - val_loss: 46.5525\n",
      "Epoch 311/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1411 - val_loss: 46.6943\n",
      "Epoch 312/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0749 - val_loss: 47.1053\n",
      "Epoch 313/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0853 - val_loss: 47.4069\n",
      "Epoch 314/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2866 - val_loss: 47.2083\n",
      "Epoch 315/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2731 - val_loss: 46.3099\n",
      "Epoch 316/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2370 - val_loss: 46.9847\n",
      "Epoch 317/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9935 - val_loss: 46.9006\n",
      "Epoch 318/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0974 - val_loss: 46.6584\n",
      "Epoch 319/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0685 - val_loss: 54.7426\n",
      "Epoch 320/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1483 - val_loss: 46.9466\n",
      "Epoch 321/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0255 - val_loss: 46.6198\n",
      "Epoch 322/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1203 - val_loss: 48.9719\n",
      "Epoch 323/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1260 - val_loss: 47.6627\n",
      "Epoch 324/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2584 - val_loss: 46.2958\n",
      "Epoch 325/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4131 - val_loss: 47.0668\n",
      "Epoch 326/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8775 - val_loss: 46.2239\n",
      "Epoch 327/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0188 - val_loss: 47.8519\n",
      "Epoch 328/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9891 - val_loss: 46.4868\n",
      "Epoch 329/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2019 - val_loss: 46.4201\n",
      "Epoch 330/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0730 - val_loss: 46.7155\n",
      "Epoch 331/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8742 - val_loss: 47.7800\n",
      "Epoch 332/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0519 - val_loss: 46.8595\n",
      "Epoch 333/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8990 - val_loss: 46.2292\n",
      "Epoch 334/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0062 - val_loss: 48.7761\n",
      "Epoch 335/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9844 - val_loss: 46.2136\n",
      "Epoch 336/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0738 - val_loss: 46.6277\n",
      "Epoch 337/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9197 - val_loss: 56.0398\n",
      "Epoch 338/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0977 - val_loss: 46.8225\n",
      "Epoch 339/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2766 - val_loss: 46.3840\n",
      "Epoch 340/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2972 - val_loss: 46.8373\n",
      "Epoch 341/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0266 - val_loss: 47.7563\n",
      "Epoch 342/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0100 - val_loss: 49.1231\n",
      "Epoch 343/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9577 - val_loss: 46.5583\n",
      "Epoch 344/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0259 - val_loss: 48.2518\n",
      "Epoch 345/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5720 - val_loss: 46.6876\n",
      "Epoch 346/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0558 - val_loss: 48.1746\n",
      "Epoch 347/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9437 - val_loss: 47.3753\n",
      "Epoch 348/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2672 - val_loss: 49.0434\n",
      "Epoch 349/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9858 - val_loss: 46.6871\n",
      "Epoch 350/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0272 - val_loss: 46.3813\n",
      "Epoch 351/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9120 - val_loss: 46.3706\n",
      "Epoch 352/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9024 - val_loss: 48.0649\n",
      "Epoch 353/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0764 - val_loss: 47.6326\n",
      "Epoch 354/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7843 - val_loss: 46.3863\n",
      "Epoch 355/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2903 - val_loss: 48.6259\n",
      "Epoch 356/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7479 - val_loss: 47.1575\n",
      "Epoch 357/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2891 - val_loss: 46.3108\n",
      "Epoch 358/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.1129 - val_loss: 46.9664\n",
      "Epoch 359/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2043 - val_loss: 46.1095\n",
      "Epoch 360/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9248 - val_loss: 46.2187\n",
      "Epoch 361/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0766 - val_loss: 46.8073\n",
      "Epoch 362/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9409 - val_loss: 48.9999\n",
      "Epoch 363/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1369 - val_loss: 46.4239\n",
      "Epoch 364/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8431 - val_loss: 46.3329\n",
      "Epoch 365/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9419 - val_loss: 46.9578\n",
      "Epoch 366/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8436 - val_loss: 46.5115\n",
      "Epoch 367/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9982 - val_loss: 49.4527\n",
      "Epoch 368/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8614 - val_loss: 48.5661\n",
      "Epoch 369/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5993 - val_loss: 46.9588\n",
      "Epoch 370/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0350 - val_loss: 46.2710\n",
      "Epoch 371/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7637 - val_loss: 46.6704\n",
      "Epoch 372/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9092 - val_loss: 47.4633\n",
      "Epoch 373/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7867 - val_loss: 46.8935\n",
      "Epoch 374/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7163 - val_loss: 47.1958\n",
      "Epoch 375/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7379 - val_loss: 46.2853\n",
      "Epoch 376/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7874 - val_loss: 47.2824\n",
      "Epoch 377/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7339 - val_loss: 46.9410\n",
      "Epoch 378/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8068 - val_loss: 47.0731\n",
      "Epoch 379/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0978 - val_loss: 46.5171\n",
      "Epoch 380/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8200 - val_loss: 46.5312\n",
      "Epoch 381/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8834 - val_loss: 46.1664\n",
      "Epoch 382/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8439 - val_loss: 46.7215\n",
      "Epoch 383/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9453 - val_loss: 46.2355\n",
      "Epoch 384/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7293 - val_loss: 47.5323\n",
      "Epoch 385/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0605 - val_loss: 46.2035\n",
      "Epoch 386/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7511 - val_loss: 46.0758\n",
      "Epoch 387/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6776 - val_loss: 51.1648\n",
      "Epoch 388/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9326 - val_loss: 46.5211\n",
      "Epoch 389/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6645 - val_loss: 46.3932\n",
      "Epoch 390/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7602 - val_loss: 46.4791\n",
      "Epoch 391/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1096 - val_loss: 47.6961\n",
      "Epoch 392/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6856 - val_loss: 46.6122\n",
      "Epoch 393/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0265 - val_loss: 46.4207\n",
      "Epoch 394/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7092 - val_loss: 46.5400\n",
      "Epoch 395/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9180 - val_loss: 47.6014\n",
      "Epoch 396/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7112 - val_loss: 46.1023\n",
      "Epoch 397/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8448 - val_loss: 46.1523\n",
      "Epoch 398/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9510 - val_loss: 46.4443\n",
      "Epoch 399/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8918 - val_loss: 46.6561\n",
      "Epoch 400/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9881 - val_loss: 46.2678\n",
      "Epoch 401/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9013 - val_loss: 47.9815\n",
      "Epoch 402/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1071 - val_loss: 53.8695\n",
      "Epoch 403/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8694 - val_loss: 46.7267\n",
      "Epoch 404/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2104 - val_loss: 46.2260\n",
      "Epoch 405/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5986 - val_loss: 48.4357\n",
      "Epoch 406/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7979 - val_loss: 46.5602\n",
      "Epoch 407/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8547 - val_loss: 46.3131\n",
      "Epoch 408/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0220 - val_loss: 49.9831\n",
      "Epoch 409/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9281 - val_loss: 46.4764\n",
      "Epoch 410/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1067 - val_loss: 46.9025\n",
      "Epoch 411/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6679 - val_loss: 46.1943\n",
      "Epoch 412/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8470 - val_loss: 46.5474\n",
      "Epoch 413/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7017 - val_loss: 46.6461\n",
      "Epoch 414/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2990 - val_loss: 46.5814\n",
      "Epoch 415/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1892 - val_loss: 46.7607\n",
      "Epoch 416/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0419 - val_loss: 46.5965\n",
      "Epoch 417/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2549 - val_loss: 46.2363\n",
      "Epoch 418/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8043 - val_loss: 47.1383\n",
      "Epoch 419/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7776 - val_loss: 46.3260\n",
      "Epoch 420/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.8497 - val_loss: 46.4129\n",
      "Epoch 421/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6302 - val_loss: 46.6002\n",
      "Epoch 422/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6002 - val_loss: 46.0298\n",
      "Epoch 423/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0958 - val_loss: 46.8971\n",
      "Epoch 424/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6738 - val_loss: 46.6646\n",
      "Epoch 425/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6409 - val_loss: 48.2743\n",
      "Epoch 426/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7761 - val_loss: 47.8781\n",
      "Epoch 427/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4833 - val_loss: 46.1419\n",
      "Epoch 428/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9552 - val_loss: 47.0951\n",
      "Epoch 429/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8440 - val_loss: 49.5520\n",
      "Epoch 430/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9035 - val_loss: 46.6544\n",
      "Epoch 431/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3992 - val_loss: 46.2789\n",
      "Epoch 432/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8344 - val_loss: 46.3676\n",
      "Epoch 433/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6626 - val_loss: 46.5922\n",
      "Epoch 434/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6459 - val_loss: 47.8122\n",
      "Epoch 435/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6927 - val_loss: 46.7484\n",
      "Epoch 436/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.1763 - val_loss: 46.0920\n",
      "Epoch 437/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8552 - val_loss: 46.1407\n",
      "Epoch 438/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7479 - val_loss: 46.6928\n",
      "Epoch 439/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7912 - val_loss: 46.9391\n",
      "Epoch 440/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5992 - val_loss: 46.3022\n",
      "Epoch 441/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7257 - val_loss: 46.2091\n",
      "Epoch 442/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5477 - val_loss: 46.6193\n",
      "Epoch 443/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0124 - val_loss: 46.4671\n",
      "Epoch 444/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7724 - val_loss: 46.3326\n",
      "Epoch 445/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7434 - val_loss: 46.1336\n",
      "Epoch 446/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8802 - val_loss: 46.2715\n",
      "Epoch 447/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5118 - val_loss: 46.4172\n",
      "Epoch 448/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5313 - val_loss: 46.7431\n",
      "Epoch 449/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7691 - val_loss: 46.2432\n",
      "Epoch 450/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6597 - val_loss: 46.0260\n",
      "Epoch 451/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7616 - val_loss: 54.5056\n",
      "Epoch 452/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7522 - val_loss: 48.4645\n",
      "Epoch 453/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6531 - val_loss: 48.4061\n",
      "Epoch 454/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5689 - val_loss: 46.1573\n",
      "Epoch 455/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5510 - val_loss: 46.2677\n",
      "Epoch 456/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6108 - val_loss: 47.5517\n",
      "Epoch 457/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7599 - val_loss: 46.8550\n",
      "Epoch 458/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4519 - val_loss: 46.1935\n",
      "Epoch 459/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5996 - val_loss: 46.0135\n",
      "Epoch 460/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6721 - val_loss: 46.5663\n",
      "Epoch 461/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6137 - val_loss: 47.1611\n",
      "Epoch 462/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6841 - val_loss: 45.9625\n",
      "Epoch 463/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5533 - val_loss: 46.0757\n",
      "Epoch 464/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3410 - val_loss: 46.0694\n",
      "Epoch 465/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6095 - val_loss: 48.0039\n",
      "Epoch 466/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5993 - val_loss: 47.5329\n",
      "Epoch 467/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6966 - val_loss: 46.2869\n",
      "Epoch 468/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6844 - val_loss: 46.2437\n",
      "Epoch 469/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7158 - val_loss: 46.3823\n",
      "Epoch 470/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7349 - val_loss: 49.6654\n",
      "Epoch 471/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6082 - val_loss: 46.7008\n",
      "Epoch 472/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7857 - val_loss: 46.4981\n",
      "Epoch 473/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6696 - val_loss: 45.9978\n",
      "Epoch 474/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7038 - val_loss: 47.1462\n",
      "Epoch 475/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5628 - val_loss: 45.9997\n",
      "Epoch 476/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.5421 - val_loss: 46.6018\n",
      "Epoch 477/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8615 - val_loss: 46.3334\n",
      "Epoch 478/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5727 - val_loss: 47.9639\n",
      "Epoch 479/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5083 - val_loss: 46.1264\n",
      "Epoch 480/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4234 - val_loss: 46.6137\n",
      "Epoch 481/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8204 - val_loss: 46.3351\n",
      "Epoch 482/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6089 - val_loss: 46.5629\n",
      "Epoch 483/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6913 - val_loss: 49.2345\n",
      "Epoch 484/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0561 - val_loss: 47.8660\n",
      "Epoch 485/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7259 - val_loss: 47.6183\n",
      "Epoch 486/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9438 - val_loss: 47.1532\n",
      "Epoch 487/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7236 - val_loss: 46.4167\n",
      "Epoch 488/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4488 - val_loss: 46.7092\n",
      "Epoch 489/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4835 - val_loss: 51.0451\n",
      "Epoch 490/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6696 - val_loss: 48.5243\n",
      "Epoch 491/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4268 - val_loss: 46.5539\n",
      "Epoch 492/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4788 - val_loss: 46.1958\n",
      "Epoch 493/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6909 - val_loss: 46.2573\n",
      "Epoch 494/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.2899 - val_loss: 47.3350\n",
      "Epoch 495/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4183 - val_loss: 48.9965\n",
      "Epoch 496/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5211 - val_loss: 46.4722\n",
      "Epoch 497/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6089 - val_loss: 47.0045\n",
      "Epoch 498/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4717 - val_loss: 46.6882\n",
      "Epoch 499/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4184 - val_loss: 46.3075\n",
      "Epoch 500/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7523 - val_loss: 46.4009\n",
      "Epoch 501/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3311 - val_loss: 46.4274\n",
      "Epoch 502/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.3422 - val_loss: 49.3205\n",
      "Epoch 503/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4827 - val_loss: 46.0572\n",
      "Epoch 504/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4322 - val_loss: 46.7756\n",
      "Epoch 505/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4490 - val_loss: 49.8585\n",
      "Epoch 506/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6501 - val_loss: 46.5514\n",
      "Epoch 507/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.4317 - val_loss: 46.9053\n",
      "Epoch 508/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5582 - val_loss: 49.1769\n",
      "Epoch 509/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4821 - val_loss: 46.0628\n",
      "Epoch 510/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4284 - val_loss: 49.2067\n",
      "Epoch 511/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0131 - val_loss: 46.3079\n",
      "Epoch 512/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7160 - val_loss: 47.0873\n",
      "216/216 [==============================] - 0s 2ms/step\n",
      "861/861 [==============================] - 1s 2ms/step\n",
      "Fold 3\n",
      "Epoch 1/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 60.2075 - val_loss: 53.4638\n",
      "Epoch 2/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 53.2540 - val_loss: 53.3820\n",
      "Epoch 3/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.2945 - val_loss: 52.4244\n",
      "Epoch 4/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.7509 - val_loss: 54.1831\n",
      "Epoch 5/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 52.4238 - val_loss: 52.7786\n",
      "Epoch 6/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.6568 - val_loss: 55.7835\n",
      "Epoch 7/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.9466 - val_loss: 54.2332\n",
      "Epoch 8/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.0310 - val_loss: 52.6527\n",
      "Epoch 9/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.2759 - val_loss: 53.6529\n",
      "Epoch 10/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 52.0459 - val_loss: 54.9716\n",
      "Epoch 11/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.7954 - val_loss: 60.9040\n",
      "Epoch 12/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.8759 - val_loss: 52.4721\n",
      "Epoch 13/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.9081 - val_loss: 52.6742\n",
      "Epoch 14/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.5824 - val_loss: 53.7088\n",
      "Epoch 15/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.9208 - val_loss: 51.9937\n",
      "Epoch 16/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5292 - val_loss: 52.7368\n",
      "Epoch 17/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6961 - val_loss: 52.1815\n",
      "Epoch 18/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5686 - val_loss: 52.1725\n",
      "Epoch 19/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.6193 - val_loss: 51.9711\n",
      "Epoch 20/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.2983 - val_loss: 53.7971\n",
      "Epoch 21/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.7774 - val_loss: 52.4906\n",
      "Epoch 22/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.7146 - val_loss: 51.8271\n",
      "Epoch 23/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3784 - val_loss: 52.0920\n",
      "Epoch 24/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3694 - val_loss: 52.8644\n",
      "Epoch 25/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3534 - val_loss: 51.6964\n",
      "Epoch 26/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4526 - val_loss: 52.5201\n",
      "Epoch 27/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4144 - val_loss: 54.4988\n",
      "Epoch 28/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.5031 - val_loss: 51.7426\n",
      "Epoch 29/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.4042 - val_loss: 52.2502\n",
      "Epoch 30/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3379 - val_loss: 51.8884\n",
      "Epoch 31/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.2083 - val_loss: 51.7042\n",
      "Epoch 32/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1775 - val_loss: 53.3409\n",
      "Epoch 33/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.2175 - val_loss: 51.9331\n",
      "Epoch 34/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1960 - val_loss: 53.0898\n",
      "Epoch 35/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3961 - val_loss: 51.7906\n",
      "Epoch 36/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.2317 - val_loss: 51.7502\n",
      "Epoch 37/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9991 - val_loss: 53.6111\n",
      "Epoch 38/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.2626 - val_loss: 51.6731\n",
      "Epoch 39/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1200 - val_loss: 53.0015\n",
      "Epoch 40/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1207 - val_loss: 52.0765\n",
      "Epoch 41/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.0488 - val_loss: 55.9592\n",
      "Epoch 42/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1898 - val_loss: 51.6217\n",
      "Epoch 43/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3938 - val_loss: 52.0101\n",
      "Epoch 44/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9757 - val_loss: 51.7291\n",
      "Epoch 45/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0067 - val_loss: 52.5918\n",
      "Epoch 46/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9983 - val_loss: 53.0478\n",
      "Epoch 47/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0037 - val_loss: 51.6359\n",
      "Epoch 48/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.3183 - val_loss: 51.5524\n",
      "Epoch 49/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0652 - val_loss: 52.9744\n",
      "Epoch 50/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9340 - val_loss: 51.9706\n",
      "Epoch 51/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9013 - val_loss: 52.1144\n",
      "Epoch 52/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0164 - val_loss: 52.0100\n",
      "Epoch 53/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1824 - val_loss: 52.1189\n",
      "Epoch 54/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.2110 - val_loss: 51.8490\n",
      "Epoch 55/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0099 - val_loss: 52.3481\n",
      "Epoch 56/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.1502 - val_loss: 51.4934\n",
      "Epoch 57/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.8145 - val_loss: 51.4379\n",
      "Epoch 58/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.8780 - val_loss: 51.5015\n",
      "Epoch 59/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.9051 - val_loss: 51.8288\n",
      "Epoch 60/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0394 - val_loss: 51.8878\n",
      "Epoch 61/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.8995 - val_loss: 52.6357\n",
      "Epoch 62/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.7875 - val_loss: 51.3955\n",
      "Epoch 63/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.8618 - val_loss: 51.4154\n",
      "Epoch 64/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 51.0957 - val_loss: 51.9479\n",
      "Epoch 65/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.6438 - val_loss: 51.4061\n",
      "Epoch 66/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.7798 - val_loss: 53.8079\n",
      "Epoch 67/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.6315 - val_loss: 51.3766\n",
      "Epoch 68/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.7557 - val_loss: 51.8365\n",
      "Epoch 69/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.5235 - val_loss: 51.7903\n",
      "Epoch 70/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.7270 - val_loss: 51.3738\n",
      "Epoch 71/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 50.6612 - val_loss: 51.5758\n",
      "Epoch 72/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.8414 - val_loss: 52.2739\n",
      "Epoch 73/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.5919 - val_loss: 53.7911\n",
      "Epoch 74/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.4871 - val_loss: 51.4801\n",
      "Epoch 75/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 50.5918 - val_loss: 51.4241\n",
      "Epoch 76/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.7620 - val_loss: 51.4394\n",
      "Epoch 77/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.4609 - val_loss: 53.0573\n",
      "Epoch 78/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.3548 - val_loss: 51.0150\n",
      "Epoch 79/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.2861 - val_loss: 50.9149\n",
      "Epoch 80/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 50.1849 - val_loss: 51.8151\n",
      "Epoch 81/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.3555 - val_loss: 51.1762\n",
      "Epoch 82/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.4803 - val_loss: 51.6630\n",
      "Epoch 83/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 50.2089 - val_loss: 52.2319\n",
      "Epoch 84/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 50.2478 - val_loss: 51.5119\n",
      "Epoch 85/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.1996 - val_loss: 52.8892\n",
      "Epoch 86/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.1335 - val_loss: 51.4528\n",
      "Epoch 87/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.8278 - val_loss: 50.7008\n",
      "Epoch 88/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.1783 - val_loss: 50.5345\n",
      "Epoch 89/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.2494 - val_loss: 54.2399\n",
      "Epoch 90/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 50.2566 - val_loss: 51.0083\n",
      "Epoch 91/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 50.1241 - val_loss: 51.5867\n",
      "Epoch 92/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.9877 - val_loss: 51.1160\n",
      "Epoch 93/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.9570 - val_loss: 51.6766\n",
      "Epoch 94/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.9581 - val_loss: 50.1573\n",
      "Epoch 95/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 49.7719 - val_loss: 50.5201\n",
      "Epoch 96/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 49.9152 - val_loss: 50.6269\n",
      "Epoch 97/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.6696 - val_loss: 50.2718\n",
      "Epoch 98/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 49.7402 - val_loss: 50.7788\n",
      "Epoch 99/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.0971 - val_loss: 50.6626\n",
      "Epoch 100/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 49.7840 - val_loss: 50.6100\n",
      "Epoch 101/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.6430 - val_loss: 53.3759\n",
      "Epoch 102/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.9009 - val_loss: 51.2480\n",
      "Epoch 103/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6124 - val_loss: 51.5909\n",
      "Epoch 104/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 49.6272 - val_loss: 50.9508\n",
      "Epoch 105/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6368 - val_loss: 50.2865\n",
      "Epoch 106/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.9091 - val_loss: 50.3225\n",
      "Epoch 107/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5503 - val_loss: 50.4939\n",
      "Epoch 108/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4015 - val_loss: 50.8957\n",
      "Epoch 109/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5027 - val_loss: 49.8299\n",
      "Epoch 110/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.5124 - val_loss: 50.0271\n",
      "Epoch 111/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4057 - val_loss: 50.8614\n",
      "Epoch 112/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5358 - val_loss: 51.2460\n",
      "Epoch 113/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2868 - val_loss: 49.8324\n",
      "Epoch 114/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4242 - val_loss: 49.4157\n",
      "Epoch 115/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5102 - val_loss: 49.7415\n",
      "Epoch 116/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6241 - val_loss: 52.3386\n",
      "Epoch 117/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2486 - val_loss: 51.5385\n",
      "Epoch 118/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.4485 - val_loss: 50.2574\n",
      "Epoch 119/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.6427 - val_loss: 50.3477\n",
      "Epoch 120/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3958 - val_loss: 52.1235\n",
      "Epoch 121/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2137 - val_loss: 50.2177\n",
      "Epoch 122/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5526 - val_loss: 49.7209\n",
      "Epoch 123/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1422 - val_loss: 49.1052\n",
      "Epoch 124/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2780 - val_loss: 49.8488\n",
      "Epoch 125/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1547 - val_loss: 50.3174\n",
      "Epoch 126/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2382 - val_loss: 50.5177\n",
      "Epoch 127/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1430 - val_loss: 49.9618\n",
      "Epoch 128/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.4820 - val_loss: 50.2882\n",
      "Epoch 129/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1881 - val_loss: 49.8263\n",
      "Epoch 130/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.5073 - val_loss: 50.1432\n",
      "Epoch 131/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.3352 - val_loss: 50.8342\n",
      "Epoch 132/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1244 - val_loss: 48.9340\n",
      "Epoch 133/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2039 - val_loss: 49.6356\n",
      "Epoch 134/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0943 - val_loss: 49.6589\n",
      "Epoch 135/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.2807 - val_loss: 50.6445\n",
      "Epoch 136/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0073 - val_loss: 51.3853\n",
      "Epoch 137/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.1381 - val_loss: 49.6256\n",
      "Epoch 138/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8596 - val_loss: 50.7031\n",
      "Epoch 139/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0069 - val_loss: 49.5366\n",
      "Epoch 140/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.9395 - val_loss: 50.4393\n",
      "Epoch 141/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9904 - val_loss: 49.6886\n",
      "Epoch 142/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0342 - val_loss: 48.8207\n",
      "Epoch 143/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.7929 - val_loss: 51.3637\n",
      "Epoch 144/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9377 - val_loss: 49.6213\n",
      "Epoch 145/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.0715 - val_loss: 51.2913\n",
      "Epoch 146/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9594 - val_loss: 49.7268\n",
      "Epoch 147/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8048 - val_loss: 50.8155\n",
      "Epoch 148/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9874 - val_loss: 50.0910\n",
      "Epoch 149/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7110 - val_loss: 49.5728\n",
      "Epoch 150/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9194 - val_loss: 51.8715\n",
      "Epoch 151/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9638 - val_loss: 49.1363\n",
      "Epoch 152/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7864 - val_loss: 49.8830\n",
      "Epoch 153/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8059 - val_loss: 49.0965\n",
      "Epoch 154/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 49.0785 - val_loss: 50.1248\n",
      "Epoch 155/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8595 - val_loss: 49.5540\n",
      "Epoch 156/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5385 - val_loss: 49.0478\n",
      "Epoch 157/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7843 - val_loss: 50.1230\n",
      "Epoch 158/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3772 - val_loss: 49.2819\n",
      "Epoch 159/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.9853 - val_loss: 50.3137\n",
      "Epoch 160/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5105 - val_loss: 50.0361\n",
      "Epoch 161/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7460 - val_loss: 48.7464\n",
      "Epoch 162/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5395 - val_loss: 50.5101\n",
      "Epoch 163/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6744 - val_loss: 49.2613\n",
      "Epoch 164/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5149 - val_loss: 48.8538\n",
      "Epoch 165/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.7233 - val_loss: 49.0956\n",
      "Epoch 166/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.6083 - val_loss: 49.7051\n",
      "Epoch 167/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5278 - val_loss: 48.9966\n",
      "Epoch 168/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5658 - val_loss: 49.0308\n",
      "Epoch 169/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1483 - val_loss: 49.0246\n",
      "Epoch 170/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4092 - val_loss: 49.2693\n",
      "Epoch 171/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2254 - val_loss: 49.1100\n",
      "Epoch 172/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6016 - val_loss: 50.0733\n",
      "Epoch 173/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2893 - val_loss: 49.6565\n",
      "Epoch 174/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.1636 - val_loss: 49.6736\n",
      "Epoch 175/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3455 - val_loss: 50.8973\n",
      "Epoch 176/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.5485 - val_loss: 51.2965\n",
      "Epoch 177/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.8620 - val_loss: 49.6545\n",
      "Epoch 178/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4832 - val_loss: 50.6440\n",
      "Epoch 179/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.3264 - val_loss: 48.2352\n",
      "Epoch 180/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3487 - val_loss: 51.2853\n",
      "Epoch 181/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5093 - val_loss: 48.8484\n",
      "Epoch 182/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4234 - val_loss: 50.1755\n",
      "Epoch 183/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4832 - val_loss: 49.8772\n",
      "Epoch 184/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.6716 - val_loss: 49.3810\n",
      "Epoch 185/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4499 - val_loss: 52.9668\n",
      "Epoch 186/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3471 - val_loss: 49.3974\n",
      "Epoch 187/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1786 - val_loss: 52.7444\n",
      "Epoch 188/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4133 - val_loss: 48.9433\n",
      "Epoch 189/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2846 - val_loss: 57.7629\n",
      "Epoch 190/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4880 - val_loss: 51.9262\n",
      "Epoch 191/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.6919 - val_loss: 48.8975\n",
      "Epoch 192/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5269 - val_loss: 48.8693\n",
      "Epoch 193/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.4016 - val_loss: 48.9813\n",
      "Epoch 194/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.5457 - val_loss: 48.6666\n",
      "Epoch 195/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1599 - val_loss: 48.4204\n",
      "Epoch 196/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5090 - val_loss: 49.2684\n",
      "Epoch 197/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.4837 - val_loss: 48.6877\n",
      "Epoch 198/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2413 - val_loss: 49.1795\n",
      "Epoch 199/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1395 - val_loss: 48.6360\n",
      "Epoch 200/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.3365 - val_loss: 50.0975\n",
      "Epoch 201/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1265 - val_loss: 48.6749\n",
      "Epoch 202/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.3167 - val_loss: 49.3643\n",
      "Epoch 203/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.3971 - val_loss: 51.5944\n",
      "Epoch 204/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3270 - val_loss: 49.5010\n",
      "Epoch 205/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.0653 - val_loss: 49.1478\n",
      "Epoch 206/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.1894 - val_loss: 50.6719\n",
      "Epoch 207/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.3322 - val_loss: 49.6212\n",
      "Epoch 208/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5254 - val_loss: 48.7786\n",
      "Epoch 209/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.2730 - val_loss: 49.6379\n",
      "Epoch 210/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0335 - val_loss: 55.1410\n",
      "Epoch 211/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.2892 - val_loss: 48.2590\n",
      "Epoch 212/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.2266 - val_loss: 49.8015\n",
      "Epoch 213/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3296 - val_loss: 48.1246\n",
      "Epoch 214/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.3536 - val_loss: 49.1810\n",
      "Epoch 215/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.0415 - val_loss: 49.8256\n",
      "Epoch 216/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0549 - val_loss: 48.9102\n",
      "Epoch 217/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2235 - val_loss: 50.0323\n",
      "Epoch 218/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0622 - val_loss: 49.2906\n",
      "Epoch 219/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1589 - val_loss: 49.3249\n",
      "Epoch 220/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.2469 - val_loss: 48.8328\n",
      "Epoch 221/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.0993 - val_loss: 48.6156\n",
      "Epoch 222/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1205 - val_loss: 49.1937\n",
      "Epoch 223/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8728 - val_loss: 53.4087\n",
      "Epoch 224/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.2702 - val_loss: 48.3705\n",
      "Epoch 225/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3139 - val_loss: 49.1727\n",
      "Epoch 226/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0119 - val_loss: 48.2994\n",
      "Epoch 227/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2691 - val_loss: 49.3808\n",
      "Epoch 228/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1819 - val_loss: 49.9560\n",
      "Epoch 229/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.1828 - val_loss: 51.6113\n",
      "Epoch 230/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1524 - val_loss: 49.0914\n",
      "Epoch 231/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.3348 - val_loss: 49.8458\n",
      "Epoch 232/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0308 - val_loss: 48.8937\n",
      "Epoch 233/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.6268 - val_loss: 48.5657\n",
      "Epoch 234/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0730 - val_loss: 50.0928\n",
      "Epoch 235/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8574 - val_loss: 48.3785\n",
      "Epoch 236/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.2705 - val_loss: 48.7239\n",
      "Epoch 237/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0529 - val_loss: 49.1773\n",
      "Epoch 238/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8990 - val_loss: 48.0327\n",
      "Epoch 239/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0393 - val_loss: 48.5076\n",
      "Epoch 240/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9085 - val_loss: 49.0963\n",
      "Epoch 241/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0479 - val_loss: 50.1913\n",
      "Epoch 242/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0997 - val_loss: 48.7442\n",
      "Epoch 243/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1714 - val_loss: 48.3885\n",
      "Epoch 244/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9402 - val_loss: 49.5579\n",
      "Epoch 245/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9981 - val_loss: 49.3387\n",
      "Epoch 246/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.9408 - val_loss: 48.1861\n",
      "Epoch 247/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0137 - val_loss: 49.5779\n",
      "Epoch 248/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8458 - val_loss: 48.2900\n",
      "Epoch 249/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9274 - val_loss: 48.4536\n",
      "Epoch 250/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.0755 - val_loss: 48.7684\n",
      "Epoch 251/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9025 - val_loss: 47.8775\n",
      "Epoch 252/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7377 - val_loss: 47.9534\n",
      "Epoch 253/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9502 - val_loss: 48.2795\n",
      "Epoch 254/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.9740 - val_loss: 49.3281\n",
      "Epoch 255/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0718 - val_loss: 49.5413\n",
      "Epoch 256/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6846 - val_loss: 48.9554\n",
      "Epoch 257/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.1445 - val_loss: 52.1932\n",
      "Epoch 258/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8882 - val_loss: 47.8619\n",
      "Epoch 259/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9115 - val_loss: 48.2523\n",
      "Epoch 260/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.9594 - val_loss: 48.3148\n",
      "Epoch 261/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.6375 - val_loss: 49.3322\n",
      "Epoch 262/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8213 - val_loss: 48.5743\n",
      "Epoch 263/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.7707 - val_loss: 49.4863\n",
      "Epoch 264/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6839 - val_loss: 49.8340\n",
      "Epoch 265/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7834 - val_loss: 50.0929\n",
      "Epoch 266/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8023 - val_loss: 48.3983\n",
      "Epoch 267/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8667 - val_loss: 48.4865\n",
      "Epoch 268/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9284 - val_loss: 48.5893\n",
      "Epoch 269/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8633 - val_loss: 48.3576\n",
      "Epoch 270/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7361 - val_loss: 49.8809\n",
      "Epoch 271/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.9602 - val_loss: 51.1482\n",
      "Epoch 272/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0022 - val_loss: 51.9656\n",
      "Epoch 273/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8665 - val_loss: 47.8719\n",
      "Epoch 274/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 48.0944 - val_loss: 51.9272\n",
      "Epoch 275/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9393 - val_loss: 47.9770\n",
      "Epoch 276/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7664 - val_loss: 48.1648\n",
      "Epoch 277/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.5411 - val_loss: 49.8880\n",
      "Epoch 278/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0604 - val_loss: 48.0125\n",
      "Epoch 279/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.9246 - val_loss: 48.5855\n",
      "Epoch 280/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.7211 - val_loss: 47.9924\n",
      "Epoch 281/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.3463 - val_loss: 50.5240\n",
      "Epoch 282/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8194 - val_loss: 48.6160\n",
      "Epoch 283/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.1819 - val_loss: 47.7971\n",
      "Epoch 284/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9165 - val_loss: 49.2094\n",
      "Epoch 285/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.0748 - val_loss: 48.4222\n",
      "Epoch 286/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8168 - val_loss: 49.1905\n",
      "Epoch 287/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9314 - val_loss: 47.7866\n",
      "Epoch 288/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5361 - val_loss: 50.4399\n",
      "Epoch 289/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.9025 - val_loss: 50.6621\n",
      "Epoch 290/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.8570 - val_loss: 49.1401\n",
      "Epoch 291/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7538 - val_loss: 49.4246\n",
      "Epoch 292/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.8411 - val_loss: 48.1639\n",
      "Epoch 293/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8442 - val_loss: 49.1854\n",
      "Epoch 294/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.8470 - val_loss: 49.1547\n",
      "Epoch 295/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.7847 - val_loss: 48.0852\n",
      "Epoch 296/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5907 - val_loss: 49.6825\n",
      "Epoch 297/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5868 - val_loss: 48.0353\n",
      "Epoch 298/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6299 - val_loss: 48.2427\n",
      "Epoch 299/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7653 - val_loss: 48.5542\n",
      "Epoch 300/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9383 - val_loss: 48.4586\n",
      "Epoch 301/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.4553 - val_loss: 49.3779\n",
      "Epoch 302/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6497 - val_loss: 50.0705\n",
      "Epoch 303/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6565 - val_loss: 47.8557\n",
      "Epoch 304/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.6065 - val_loss: 52.2743\n",
      "Epoch 305/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5960 - val_loss: 48.3284\n",
      "Epoch 306/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6225 - val_loss: 48.0250\n",
      "Epoch 307/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7359 - val_loss: 48.3391\n",
      "Epoch 308/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7577 - val_loss: 49.3192\n",
      "Epoch 309/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8967 - val_loss: 48.6400\n",
      "Epoch 310/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.9159 - val_loss: 48.7095\n",
      "Epoch 311/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.5856 - val_loss: 48.1492\n",
      "Epoch 312/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6440 - val_loss: 50.1642\n",
      "Epoch 313/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5364 - val_loss: 48.0597\n",
      "Epoch 314/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6512 - val_loss: 47.8865\n",
      "Epoch 315/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4708 - val_loss: 48.8923\n",
      "Epoch 316/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7419 - val_loss: 48.1830\n",
      "Epoch 317/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3514 - val_loss: 48.4726\n",
      "Epoch 318/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.5143 - val_loss: 47.7755\n",
      "Epoch 319/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4937 - val_loss: 49.8543\n",
      "Epoch 320/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.4299 - val_loss: 48.8283\n",
      "Epoch 321/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.7871 - val_loss: 48.1567\n",
      "Epoch 322/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9140 - val_loss: 48.2322\n",
      "Epoch 323/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6017 - val_loss: 47.8569\n",
      "Epoch 324/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.7335 - val_loss: 48.0890\n",
      "Epoch 325/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6881 - val_loss: 48.1468\n",
      "Epoch 326/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.6296 - val_loss: 49.1131\n",
      "Epoch 327/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.5762 - val_loss: 49.0246\n",
      "Epoch 328/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6235 - val_loss: 48.5771\n",
      "Epoch 329/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.6821 - val_loss: 47.9308\n",
      "Epoch 330/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7964 - val_loss: 47.9529\n",
      "Epoch 331/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.3975 - val_loss: 49.5567\n",
      "Epoch 332/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4677 - val_loss: 49.6628\n",
      "Epoch 333/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3783 - val_loss: 50.2847\n",
      "Epoch 334/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8686 - val_loss: 48.3769\n",
      "Epoch 335/10000\n",
      "646/646 [==============================] - 3s 5ms/step - loss: 47.4587 - val_loss: 48.3249\n",
      "Epoch 336/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.4040 - val_loss: 48.7183\n",
      "Epoch 337/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5672 - val_loss: 48.5911\n",
      "Epoch 338/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4381 - val_loss: 48.3067\n",
      "Epoch 339/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4962 - val_loss: 48.4301\n",
      "Epoch 340/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.6809 - val_loss: 48.3089\n",
      "Epoch 341/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3865 - val_loss: 47.8065\n",
      "Epoch 342/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.7027 - val_loss: 47.6832\n",
      "Epoch 343/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2570 - val_loss: 48.5333\n",
      "Epoch 344/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5264 - val_loss: 48.7529\n",
      "Epoch 345/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6010 - val_loss: 48.1744\n",
      "Epoch 346/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2444 - val_loss: 47.8352\n",
      "Epoch 347/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5778 - val_loss: 49.2423\n",
      "Epoch 348/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6110 - val_loss: 48.8030\n",
      "Epoch 349/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6392 - val_loss: 48.0109\n",
      "Epoch 350/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.4100 - val_loss: 48.1311\n",
      "Epoch 351/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6208 - val_loss: 48.8664\n",
      "Epoch 352/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.3381 - val_loss: 47.5345\n",
      "Epoch 353/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5475 - val_loss: 50.7425\n",
      "Epoch 354/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.5469 - val_loss: 48.3203\n",
      "Epoch 355/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4006 - val_loss: 50.0857\n",
      "Epoch 356/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4612 - val_loss: 48.3768\n",
      "Epoch 357/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4076 - val_loss: 47.6986\n",
      "Epoch 358/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3630 - val_loss: 48.2170\n",
      "Epoch 359/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.4518 - val_loss: 47.8296\n",
      "Epoch 360/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1957 - val_loss: 48.0705\n",
      "Epoch 361/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.5194 - val_loss: 48.3631\n",
      "Epoch 362/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3757 - val_loss: 48.5088\n",
      "Epoch 363/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2305 - val_loss: 48.6705\n",
      "Epoch 364/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.1821 - val_loss: 47.7085\n",
      "Epoch 365/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3179 - val_loss: 53.0956\n",
      "Epoch 366/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4456 - val_loss: 50.3419\n",
      "Epoch 367/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5887 - val_loss: 49.4480\n",
      "Epoch 368/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3317 - val_loss: 49.3837\n",
      "Epoch 369/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2707 - val_loss: 47.6686\n",
      "Epoch 370/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.4733 - val_loss: 50.0942\n",
      "Epoch 371/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1604 - val_loss: 47.5271\n",
      "Epoch 372/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7407 - val_loss: 47.6918\n",
      "Epoch 373/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4199 - val_loss: 47.7891\n",
      "Epoch 374/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3433 - val_loss: 49.1424\n",
      "Epoch 375/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2537 - val_loss: 48.2136\n",
      "Epoch 376/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3984 - val_loss: 48.1461\n",
      "Epoch 377/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2919 - val_loss: 48.2577\n",
      "Epoch 378/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2660 - val_loss: 48.1723\n",
      "Epoch 379/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4259 - val_loss: 48.4127\n",
      "Epoch 380/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4393 - val_loss: 47.6126\n",
      "Epoch 381/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.4556 - val_loss: 49.7105\n",
      "Epoch 382/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3255 - val_loss: 47.5559\n",
      "Epoch 383/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1645 - val_loss: 48.1855\n",
      "Epoch 384/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3435 - val_loss: 48.1767\n",
      "Epoch 385/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5200 - val_loss: 48.5910\n",
      "Epoch 386/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3407 - val_loss: 48.5862\n",
      "Epoch 387/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1446 - val_loss: 49.2301\n",
      "Epoch 388/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3130 - val_loss: 47.9559\n",
      "Epoch 389/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4282 - val_loss: 48.1530\n",
      "Epoch 390/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4346 - val_loss: 47.5452\n",
      "Epoch 391/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 47.6725 - val_loss: 49.6549\n",
      "Epoch 392/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2598 - val_loss: 49.1460\n",
      "Epoch 393/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1568 - val_loss: 47.8094\n",
      "Epoch 394/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2525 - val_loss: 49.1654\n",
      "Epoch 395/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1821 - val_loss: 47.6965\n",
      "Epoch 396/10000\n",
      "646/646 [==============================] - 4s 7ms/step - loss: 47.0094 - val_loss: 48.4295\n",
      "Epoch 397/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1399 - val_loss: 47.5814\n",
      "Epoch 398/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1887 - val_loss: 49.1229\n",
      "Epoch 399/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1249 - val_loss: 49.9846\n",
      "Epoch 400/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.0477 - val_loss: 51.4710\n",
      "Epoch 401/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2330 - val_loss: 48.9730\n",
      "Epoch 402/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5010 - val_loss: 48.2911\n",
      "Epoch 403/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.0755 - val_loss: 48.6688\n",
      "Epoch 404/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2041 - val_loss: 47.7353\n",
      "Epoch 405/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.0616 - val_loss: 48.2050\n",
      "Epoch 406/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4473 - val_loss: 48.2293\n",
      "Epoch 407/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4063 - val_loss: 48.3465\n",
      "Epoch 408/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4715 - val_loss: 47.5977\n",
      "Epoch 409/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1746 - val_loss: 47.8360\n",
      "Epoch 410/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2837 - val_loss: 47.6646\n",
      "Epoch 411/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 46.9211 - val_loss: 48.1531\n",
      "Epoch 412/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1347 - val_loss: 47.7306\n",
      "Epoch 413/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2425 - val_loss: 48.2558\n",
      "Epoch 414/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3375 - val_loss: 49.9506\n",
      "Epoch 415/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1692 - val_loss: 48.1655\n",
      "Epoch 416/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.3328 - val_loss: 48.4539\n",
      "Epoch 417/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1273 - val_loss: 48.2141\n",
      "Epoch 418/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1326 - val_loss: 48.5621\n",
      "Epoch 419/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.1647 - val_loss: 49.0051\n",
      "Epoch 420/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5765 - val_loss: 49.5550\n",
      "Epoch 421/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.2558 - val_loss: 48.7198\n",
      "216/216 [==============================] - 0s 2ms/step\n",
      "861/861 [==============================] - 2s 2ms/step\n",
      "Fold 4\n",
      "Epoch 1/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 59.0154 - val_loss: 57.4687\n",
      "Epoch 2/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 53.8704 - val_loss: 52.3237\n",
      "Epoch 3/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.8744 - val_loss: 51.3412\n",
      "Epoch 4/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 53.2321 - val_loss: 55.4657\n",
      "Epoch 5/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 53.1784 - val_loss: 51.2831\n",
      "Epoch 6/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.6618 - val_loss: 58.0713\n",
      "Epoch 7/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.4324 - val_loss: 51.2265\n",
      "Epoch 8/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.6990 - val_loss: 50.9645\n",
      "Epoch 9/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.1965 - val_loss: 51.4994\n",
      "Epoch 10/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.2574 - val_loss: 51.4836\n",
      "Epoch 11/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.1306 - val_loss: 55.4373\n",
      "Epoch 12/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.3272 - val_loss: 51.0973\n",
      "Epoch 13/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.0173 - val_loss: 51.0685\n",
      "Epoch 14/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.1376 - val_loss: 53.4836\n",
      "Epoch 15/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.1918 - val_loss: 51.2017\n",
      "Epoch 16/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.9922 - val_loss: 51.0748\n",
      "Epoch 17/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.9646 - val_loss: 51.5777\n",
      "Epoch 18/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.9097 - val_loss: 52.5714\n",
      "Epoch 19/10000\n",
      "646/646 [==============================] - 4s 7ms/step - loss: 51.6348 - val_loss: 51.0328\n",
      "Epoch 20/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 52.2828 - val_loss: 53.2586\n",
      "Epoch 21/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.7162 - val_loss: 51.5796\n",
      "Epoch 22/10000\n",
      "646/646 [==============================] - 5s 7ms/step - loss: 51.7597 - val_loss: 50.7922\n",
      "Epoch 23/10000\n",
      "646/646 [==============================] - 4s 7ms/step - loss: 51.8072 - val_loss: 53.1104\n",
      "Epoch 24/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.7526 - val_loss: 51.7059\n",
      "Epoch 25/10000\n",
      "646/646 [==============================] - 4s 7ms/step - loss: 51.6865 - val_loss: 50.8221\n",
      "Epoch 26/10000\n",
      "646/646 [==============================] - 5s 7ms/step - loss: 51.6171 - val_loss: 52.5727\n",
      "Epoch 27/10000\n",
      "646/646 [==============================] - 5s 7ms/step - loss: 51.6437 - val_loss: 50.8597\n",
      "Epoch 28/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.8881 - val_loss: 50.8951\n",
      "Epoch 29/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.6340 - val_loss: 50.8157\n",
      "Epoch 30/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.4921 - val_loss: 51.3551\n",
      "Epoch 31/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.5423 - val_loss: 50.8724\n",
      "Epoch 32/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.6802 - val_loss: 51.3952\n",
      "Epoch 33/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.6086 - val_loss: 50.9191\n",
      "Epoch 34/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.5731 - val_loss: 51.4285\n",
      "Epoch 35/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.4938 - val_loss: 51.6463\n",
      "Epoch 36/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.4845 - val_loss: 50.8130\n",
      "Epoch 37/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.5015 - val_loss: 51.8869\n",
      "Epoch 38/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.3993 - val_loss: 50.9054\n",
      "Epoch 39/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.3928 - val_loss: 51.2292\n",
      "Epoch 40/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.2853 - val_loss: 51.2385\n",
      "Epoch 41/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.5846 - val_loss: 51.9805\n",
      "Epoch 42/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.3308 - val_loss: 50.9827\n",
      "Epoch 43/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.3247 - val_loss: 50.9140\n",
      "Epoch 44/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.4077 - val_loss: 52.5479\n",
      "Epoch 45/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.3833 - val_loss: 51.5825\n",
      "Epoch 46/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.2581 - val_loss: 50.6148\n",
      "Epoch 47/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.5786 - val_loss: 50.7025\n",
      "Epoch 48/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.4381 - val_loss: 51.0085\n",
      "Epoch 49/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.3098 - val_loss: 50.9506\n",
      "Epoch 50/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.2918 - val_loss: 50.9592\n",
      "Epoch 51/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.1688 - val_loss: 55.8394\n",
      "Epoch 52/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.3184 - val_loss: 51.0299\n",
      "Epoch 53/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.2221 - val_loss: 51.0728\n",
      "Epoch 54/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.4055 - val_loss: 52.8274\n",
      "Epoch 55/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.2308 - val_loss: 50.8158\n",
      "Epoch 56/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.2460 - val_loss: 50.5956\n",
      "Epoch 57/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.1487 - val_loss: 50.6699\n",
      "Epoch 58/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.2655 - val_loss: 50.4827\n",
      "Epoch 59/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.1435 - val_loss: 50.5372\n",
      "Epoch 60/10000\n",
      "646/646 [==============================] - 4s 7ms/step - loss: 51.1813 - val_loss: 51.9065\n",
      "Epoch 61/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.3110 - val_loss: 50.4194\n",
      "Epoch 62/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.2481 - val_loss: 50.4603\n",
      "Epoch 63/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.2881 - val_loss: 50.4992\n",
      "Epoch 64/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.0526 - val_loss: 51.1984\n",
      "Epoch 65/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.0229 - val_loss: 50.5767\n",
      "Epoch 66/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.2340 - val_loss: 50.7487\n",
      "Epoch 67/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.9993 - val_loss: 50.4055\n",
      "Epoch 68/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.0815 - val_loss: 50.5371\n",
      "Epoch 69/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.9730 - val_loss: 51.5487\n",
      "Epoch 70/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.8799 - val_loss: 50.2663\n",
      "Epoch 71/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.9914 - val_loss: 50.2930\n",
      "Epoch 72/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.8238 - val_loss: 50.1833\n",
      "Epoch 73/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.9764 - val_loss: 50.2207\n",
      "Epoch 74/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.9118 - val_loss: 49.9572\n",
      "Epoch 75/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.9979 - val_loss: 50.8392\n",
      "Epoch 76/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.8701 - val_loss: 50.2935\n",
      "Epoch 77/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.8197 - val_loss: 52.6689\n",
      "Epoch 78/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 51.1057 - val_loss: 50.4568\n",
      "Epoch 79/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.7242 - val_loss: 49.9786\n",
      "Epoch 80/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.7945 - val_loss: 49.7051\n",
      "Epoch 81/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.6168 - val_loss: 49.8624\n",
      "Epoch 82/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.5371 - val_loss: 50.1008\n",
      "Epoch 83/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.6288 - val_loss: 49.5592\n",
      "Epoch 84/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.6637 - val_loss: 53.7568\n",
      "Epoch 85/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.3267 - val_loss: 51.1900\n",
      "Epoch 86/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.5036 - val_loss: 49.3260\n",
      "Epoch 87/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.7389 - val_loss: 51.1597\n",
      "Epoch 88/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.3624 - val_loss: 49.5201\n",
      "Epoch 89/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.3748 - val_loss: 50.9175\n",
      "Epoch 90/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.4886 - val_loss: 50.2271\n",
      "Epoch 91/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.3907 - val_loss: 49.7874\n",
      "Epoch 92/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.2267 - val_loss: 50.2437\n",
      "Epoch 93/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.4130 - val_loss: 49.2216\n",
      "Epoch 94/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.1903 - val_loss: 54.2563\n",
      "Epoch 95/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.3994 - val_loss: 49.5885\n",
      "Epoch 96/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.4948 - val_loss: 49.5216\n",
      "Epoch 97/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.9278 - val_loss: 49.7371\n",
      "Epoch 98/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.8372 - val_loss: 51.1561\n",
      "Epoch 99/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.9667 - val_loss: 49.8066\n",
      "Epoch 100/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.0533 - val_loss: 48.9431\n",
      "Epoch 101/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.3050 - val_loss: 50.6628\n",
      "Epoch 102/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.8138 - val_loss: 48.8295\n",
      "Epoch 103/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.4100 - val_loss: 49.6013\n",
      "Epoch 104/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.9330 - val_loss: 49.3410\n",
      "Epoch 105/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.5983 - val_loss: 48.7916\n",
      "Epoch 106/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.9238 - val_loss: 49.9074\n",
      "Epoch 107/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 50.0704 - val_loss: 49.2915\n",
      "Epoch 108/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.8236 - val_loss: 48.4925\n",
      "Epoch 109/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.6965 - val_loss: 50.0171\n",
      "Epoch 110/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.9373 - val_loss: 49.6523\n",
      "Epoch 111/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.7897 - val_loss: 49.0075\n",
      "Epoch 112/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.5234 - val_loss: 48.3879\n",
      "Epoch 113/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.7287 - val_loss: 48.9431\n",
      "Epoch 114/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.5716 - val_loss: 48.6918\n",
      "Epoch 115/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.7555 - val_loss: 49.0518\n",
      "Epoch 116/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.7600 - val_loss: 50.2813\n",
      "Epoch 117/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.5517 - val_loss: 50.2220\n",
      "Epoch 118/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.3989 - val_loss: 49.8833\n",
      "Epoch 119/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.4574 - val_loss: 51.2344\n",
      "Epoch 120/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.5688 - val_loss: 48.9832\n",
      "Epoch 121/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.2324 - val_loss: 49.7201\n",
      "Epoch 122/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.5643 - val_loss: 50.8673\n",
      "Epoch 123/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.2346 - val_loss: 50.8142\n",
      "Epoch 124/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.1097 - val_loss: 49.2749\n",
      "Epoch 125/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.5218 - val_loss: 49.8559\n",
      "Epoch 126/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.4592 - val_loss: 50.1930\n",
      "Epoch 127/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.5991 - val_loss: 49.0166\n",
      "Epoch 128/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.0674 - val_loss: 49.2616\n",
      "Epoch 129/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.4338 - val_loss: 48.0356\n",
      "Epoch 130/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.3707 - val_loss: 49.0595\n",
      "Epoch 131/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.5365 - val_loss: 49.2890\n",
      "Epoch 132/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.3279 - val_loss: 48.3517\n",
      "Epoch 133/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.5102 - val_loss: 52.6227\n",
      "Epoch 134/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.4012 - val_loss: 48.4857\n",
      "Epoch 135/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.2819 - val_loss: 49.0240\n",
      "Epoch 136/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.9841 - val_loss: 48.2118\n",
      "Epoch 137/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.3638 - val_loss: 48.5394\n",
      "Epoch 138/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.3638 - val_loss: 53.7749\n",
      "Epoch 139/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.2085 - val_loss: 48.4147\n",
      "Epoch 140/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.2746 - val_loss: 50.1971\n",
      "Epoch 141/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.2045 - val_loss: 48.1901\n",
      "Epoch 142/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.1742 - val_loss: 48.3805\n",
      "Epoch 143/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.1807 - val_loss: 48.9825\n",
      "Epoch 144/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.0538 - val_loss: 47.9704\n",
      "Epoch 145/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.9373 - val_loss: 49.0766\n",
      "Epoch 146/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.4374 - val_loss: 48.2169\n",
      "Epoch 147/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.0236 - val_loss: 48.7137\n",
      "Epoch 148/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8956 - val_loss: 48.9238\n",
      "Epoch 149/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.3093 - val_loss: 48.3735\n",
      "Epoch 150/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.9364 - val_loss: 50.0225\n",
      "Epoch 151/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.2407 - val_loss: 48.8318\n",
      "Epoch 152/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.1721 - val_loss: 52.5168\n",
      "Epoch 153/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.4406 - val_loss: 54.2965\n",
      "Epoch 154/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.3834 - val_loss: 48.6264\n",
      "Epoch 155/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.7220 - val_loss: 48.2707\n",
      "Epoch 156/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.7307 - val_loss: 48.2174\n",
      "Epoch 157/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8620 - val_loss: 48.8006\n",
      "Epoch 158/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5617 - val_loss: 49.1633\n",
      "Epoch 159/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.7067 - val_loss: 50.1881\n",
      "Epoch 160/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.1622 - val_loss: 48.3320\n",
      "Epoch 161/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.7954 - val_loss: 48.1062\n",
      "Epoch 162/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8443 - val_loss: 48.4323\n",
      "Epoch 163/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.0894 - val_loss: 48.8115\n",
      "Epoch 164/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.2544 - val_loss: 52.5952\n",
      "Epoch 165/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.0895 - val_loss: 47.7414\n",
      "Epoch 166/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.0237 - val_loss: 50.0886\n",
      "Epoch 167/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.9620 - val_loss: 49.5247\n",
      "Epoch 168/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.1881 - val_loss: 48.0366\n",
      "Epoch 169/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.0397 - val_loss: 48.3599\n",
      "Epoch 170/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.2872 - val_loss: 48.8072\n",
      "Epoch 171/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8965 - val_loss: 48.0417\n",
      "Epoch 172/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8304 - val_loss: 47.8151\n",
      "Epoch 173/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5086 - val_loss: 49.1143\n",
      "Epoch 174/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.7699 - val_loss: 47.9622\n",
      "Epoch 175/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5325 - val_loss: 47.6398\n",
      "Epoch 176/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.7754 - val_loss: 47.8265\n",
      "Epoch 177/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.1263 - val_loss: 48.1359\n",
      "Epoch 178/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.7901 - val_loss: 51.3653\n",
      "Epoch 179/10000\n",
      "646/646 [==============================] - 5s 7ms/step - loss: 48.6374 - val_loss: 50.2507\n",
      "Epoch 180/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8833 - val_loss: 47.8625\n",
      "Epoch 181/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8925 - val_loss: 55.4525\n",
      "Epoch 182/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.6325 - val_loss: 48.0932\n",
      "Epoch 183/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3332 - val_loss: 48.6085\n",
      "Epoch 184/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5792 - val_loss: 48.9231\n",
      "Epoch 185/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5421 - val_loss: 47.9033\n",
      "Epoch 186/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.9917 - val_loss: 48.0597\n",
      "Epoch 187/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.6388 - val_loss: 49.4453\n",
      "Epoch 188/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.7915 - val_loss: 48.1089\n",
      "Epoch 189/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4475 - val_loss: 48.0728\n",
      "Epoch 190/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.6786 - val_loss: 53.0646\n",
      "Epoch 191/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8952 - val_loss: 48.1378\n",
      "Epoch 192/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 49.1001 - val_loss: 48.6522\n",
      "Epoch 193/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5173 - val_loss: 49.8833\n",
      "Epoch 194/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4967 - val_loss: 47.7800\n",
      "Epoch 195/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.7992 - val_loss: 48.7307\n",
      "Epoch 196/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.7359 - val_loss: 48.6857\n",
      "Epoch 197/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4978 - val_loss: 49.2991\n",
      "Epoch 198/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5781 - val_loss: 50.2697\n",
      "Epoch 199/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8960 - val_loss: 47.8156\n",
      "Epoch 200/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3930 - val_loss: 50.6171\n",
      "Epoch 201/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.9148 - val_loss: 48.1715\n",
      "Epoch 202/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3127 - val_loss: 50.2141\n",
      "Epoch 203/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5434 - val_loss: 47.5055\n",
      "Epoch 204/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4747 - val_loss: 47.4957\n",
      "Epoch 205/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4953 - val_loss: 48.2570\n",
      "Epoch 206/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3593 - val_loss: 48.2774\n",
      "Epoch 207/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4140 - val_loss: 47.7902\n",
      "Epoch 208/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4759 - val_loss: 47.8562\n",
      "Epoch 209/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4557 - val_loss: 47.8440\n",
      "Epoch 210/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4970 - val_loss: 48.6054\n",
      "Epoch 211/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5887 - val_loss: 49.1587\n",
      "Epoch 212/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.6089 - val_loss: 47.8379\n",
      "Epoch 213/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2204 - val_loss: 47.7680\n",
      "Epoch 214/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3296 - val_loss: 48.0062\n",
      "Epoch 215/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.6718 - val_loss: 47.7933\n",
      "Epoch 216/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.8098 - val_loss: 50.3318\n",
      "Epoch 217/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4161 - val_loss: 47.9922\n",
      "Epoch 218/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3020 - val_loss: 47.9150\n",
      "Epoch 219/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5384 - val_loss: 47.6817\n",
      "Epoch 220/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.6032 - val_loss: 47.6185\n",
      "Epoch 221/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2002 - val_loss: 47.7900\n",
      "Epoch 222/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1690 - val_loss: 47.3841\n",
      "Epoch 223/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2479 - val_loss: 47.9954\n",
      "Epoch 224/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4699 - val_loss: 47.7045\n",
      "Epoch 225/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3110 - val_loss: 48.9818\n",
      "Epoch 226/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1622 - val_loss: 49.0103\n",
      "Epoch 227/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2767 - val_loss: 50.4338\n",
      "Epoch 228/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5701 - val_loss: 47.5780\n",
      "Epoch 229/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2312 - val_loss: 49.6187\n",
      "Epoch 230/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5707 - val_loss: 49.6694\n",
      "Epoch 231/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2570 - val_loss: 49.4620\n",
      "Epoch 232/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3766 - val_loss: 47.8722\n",
      "Epoch 233/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2983 - val_loss: 48.0048\n",
      "Epoch 234/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1967 - val_loss: 47.6880\n",
      "Epoch 235/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5897 - val_loss: 49.1210\n",
      "Epoch 236/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2355 - val_loss: 47.7479\n",
      "Epoch 237/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3889 - val_loss: 47.6513\n",
      "Epoch 238/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1178 - val_loss: 48.6183\n",
      "Epoch 239/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1503 - val_loss: 47.3795\n",
      "Epoch 240/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0924 - val_loss: 48.1611\n",
      "Epoch 241/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4461 - val_loss: 47.5787\n",
      "Epoch 242/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3890 - val_loss: 51.0927\n",
      "Epoch 243/10000\n",
      "646/646 [==============================] - 4s 7ms/step - loss: 48.3181 - val_loss: 49.6726\n",
      "Epoch 244/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9717 - val_loss: 48.4474\n",
      "Epoch 245/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3658 - val_loss: 47.9123\n",
      "Epoch 246/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1756 - val_loss: 49.6196\n",
      "Epoch 247/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0802 - val_loss: 49.6009\n",
      "Epoch 248/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.4421 - val_loss: 47.4904\n",
      "Epoch 249/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1414 - val_loss: 47.3472\n",
      "Epoch 250/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3706 - val_loss: 47.6443\n",
      "Epoch 251/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2462 - val_loss: 48.1496\n",
      "Epoch 252/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9738 - val_loss: 48.5563\n",
      "Epoch 253/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5308 - val_loss: 48.1389\n",
      "Epoch 254/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5026 - val_loss: 48.5689\n",
      "Epoch 255/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0839 - val_loss: 47.9552\n",
      "Epoch 256/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1204 - val_loss: 47.4588\n",
      "Epoch 257/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.2365 - val_loss: 47.6422\n",
      "Epoch 258/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9887 - val_loss: 47.5392\n",
      "Epoch 259/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9990 - val_loss: 47.4266\n",
      "Epoch 260/10000\n",
      "646/646 [==============================] - 4s 5ms/step - loss: 48.1834 - val_loss: 48.4106\n",
      "Epoch 261/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3959 - val_loss: 47.4637\n",
      "Epoch 262/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8726 - val_loss: 47.4103\n",
      "Epoch 263/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2060 - val_loss: 47.9015\n",
      "Epoch 264/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3146 - val_loss: 48.3242\n",
      "Epoch 265/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.5215 - val_loss: 48.2765\n",
      "Epoch 266/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2250 - val_loss: 48.0632\n",
      "Epoch 267/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0792 - val_loss: 49.8809\n",
      "Epoch 268/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1182 - val_loss: 47.7207\n",
      "Epoch 269/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1136 - val_loss: 48.0003\n",
      "Epoch 270/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0980 - val_loss: 47.3209\n",
      "Epoch 271/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1163 - val_loss: 47.6834\n",
      "Epoch 272/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9042 - val_loss: 47.2401\n",
      "Epoch 273/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1564 - val_loss: 48.2595\n",
      "Epoch 274/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9423 - val_loss: 47.8388\n",
      "Epoch 275/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0767 - val_loss: 48.4641\n",
      "Epoch 276/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9694 - val_loss: 47.9858\n",
      "Epoch 277/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6613 - val_loss: 47.6274\n",
      "Epoch 278/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2034 - val_loss: 47.6233\n",
      "Epoch 279/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9891 - val_loss: 48.8226\n",
      "Epoch 280/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9559 - val_loss: 47.8002\n",
      "Epoch 281/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3019 - val_loss: 47.4217\n",
      "Epoch 282/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8114 - val_loss: 47.2835\n",
      "Epoch 283/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8890 - val_loss: 47.8117\n",
      "Epoch 284/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1942 - val_loss: 47.6545\n",
      "Epoch 285/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.2901 - val_loss: 49.8205\n",
      "Epoch 286/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8291 - val_loss: 47.2845\n",
      "Epoch 287/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9480 - val_loss: 46.9928\n",
      "Epoch 288/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.3168 - val_loss: 48.5945\n",
      "Epoch 289/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8450 - val_loss: 53.7923\n",
      "Epoch 290/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8243 - val_loss: 47.8357\n",
      "Epoch 291/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7958 - val_loss: 50.0489\n",
      "Epoch 292/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9530 - val_loss: 48.4724\n",
      "Epoch 293/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9806 - val_loss: 47.9475\n",
      "Epoch 294/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5447 - val_loss: 47.2250\n",
      "Epoch 295/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9006 - val_loss: 50.6845\n",
      "Epoch 296/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9874 - val_loss: 47.6987\n",
      "Epoch 297/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9952 - val_loss: 47.4226\n",
      "Epoch 298/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0310 - val_loss: 52.7650\n",
      "Epoch 299/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1419 - val_loss: 48.6570\n",
      "Epoch 300/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.1265 - val_loss: 47.5813\n",
      "Epoch 301/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0166 - val_loss: 53.0220\n",
      "Epoch 302/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9317 - val_loss: 49.4466\n",
      "Epoch 303/10000\n",
      "646/646 [==============================] - 4s 7ms/step - loss: 47.9658 - val_loss: 51.5123\n",
      "Epoch 304/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9518 - val_loss: 47.6384\n",
      "Epoch 305/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8452 - val_loss: 52.3420\n",
      "Epoch 306/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6078 - val_loss: 48.2298\n",
      "Epoch 307/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6168 - val_loss: 47.3241\n",
      "Epoch 308/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7967 - val_loss: 48.6617\n",
      "Epoch 309/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0404 - val_loss: 47.8945\n",
      "Epoch 310/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0482 - val_loss: 47.3169\n",
      "Epoch 311/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0351 - val_loss: 47.3891\n",
      "Epoch 312/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0718 - val_loss: 47.1655\n",
      "Epoch 313/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7323 - val_loss: 49.2680\n",
      "Epoch 314/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9698 - val_loss: 47.8617\n",
      "Epoch 315/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7082 - val_loss: 47.8309\n",
      "Epoch 316/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8691 - val_loss: 47.9425\n",
      "Epoch 317/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4982 - val_loss: 47.6008\n",
      "Epoch 318/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7013 - val_loss: 47.2800\n",
      "Epoch 319/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6547 - val_loss: 47.4234\n",
      "Epoch 320/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6510 - val_loss: 47.6194\n",
      "Epoch 321/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6697 - val_loss: 47.1208\n",
      "Epoch 322/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7461 - val_loss: 49.9570\n",
      "Epoch 323/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.4027 - val_loss: 47.0143\n",
      "Epoch 324/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0093 - val_loss: 47.4363\n",
      "Epoch 325/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.5283 - val_loss: 49.5536\n",
      "Epoch 326/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7740 - val_loss: 47.6899\n",
      "Epoch 327/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9125 - val_loss: 47.1255\n",
      "Epoch 328/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9182 - val_loss: 47.5664\n",
      "Epoch 329/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7760 - val_loss: 47.5239\n",
      "Epoch 330/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0287 - val_loss: 47.5397\n",
      "Epoch 331/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6852 - val_loss: 47.3074\n",
      "Epoch 332/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6680 - val_loss: 47.6165\n",
      "Epoch 333/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.9595 - val_loss: 47.1918\n",
      "Epoch 334/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 48.0219 - val_loss: 47.5965\n",
      "Epoch 335/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.8776 - val_loss: 47.1670\n",
      "Epoch 336/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.6803 - val_loss: 47.2310\n",
      "Epoch 337/10000\n",
      "646/646 [==============================] - 4s 6ms/step - loss: 47.7962 - val_loss: 47.2867\n",
      "216/216 [==============================] - 1s 2ms/step\n",
      "861/861 [==============================] - 2s 2ms/step\n",
      "CV score: 0.46949 \n"
     ]
    }
   ],
   "source": [
    "n_splits = 4\n",
    "random_state = 42\n",
    "\n",
    "folds = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "oof = np.zeros(len(train))\n",
    "predictions = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "    print(\"Fold {}\".format(fold_+1))\n",
    "    X_train, X_valid = X[trn_idx], X[val_idx]\n",
    "    y_train, y_valid = y[trn_idx], y[val_idx]\n",
    "    \n",
    "    # モデルの構築\n",
    "    tf.random.set_seed(42)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(1024, activation='relu', input_shape=(X.shape[1],)),\n",
    "        tf.keras.layers.Dense(512, activation='relu', input_shape=(1024,)),\n",
    "        # tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(256, activation='relu', input_shape=(512,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(256,)),\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(128,)),\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(128,)),\n",
    "        tf.keras.layers.Dense(16, activation='relu', input_shape=(64,)),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_percentage_error')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=10000, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "    oof[val_idx] = model.predict(X_valid).flatten()    \n",
    "    predictions += model.predict(X_test).flatten() / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(mean_absolute_percentage_error(y, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>drive</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>state</th>\n",
       "      <th>price</th>\n",
       "      <th>oof</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nashville</td>\n",
       "      <td>1949</td>\n",
       "      <td>bmw</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>115148</td>\n",
       "      <td>clean</td>\n",
       "      <td>manual</td>\n",
       "      <td>rwd</td>\n",
       "      <td>mid-size</td>\n",
       "      <td>convertible</td>\n",
       "      <td>orange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27587</td>\n",
       "      <td>5858.745117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>state college</td>\n",
       "      <td>2013</td>\n",
       "      <td>toyota</td>\n",
       "      <td>fair</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>172038</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>rwd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>sedan</td>\n",
       "      <td>silver</td>\n",
       "      <td>pa</td>\n",
       "      <td>4724</td>\n",
       "      <td>3304.864746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wichita</td>\n",
       "      <td>1998</td>\n",
       "      <td>ford</td>\n",
       "      <td>good</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>152492</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>fwd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>SUV</td>\n",
       "      <td>silver</td>\n",
       "      <td>ks</td>\n",
       "      <td>10931</td>\n",
       "      <td>4112.928223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>albany</td>\n",
       "      <td>2014</td>\n",
       "      <td>ford</td>\n",
       "      <td>excellent</td>\n",
       "      <td>4 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>104118</td>\n",
       "      <td>clean</td>\n",
       "      <td>manual</td>\n",
       "      <td>fwd</td>\n",
       "      <td>mid-size</td>\n",
       "      <td>SUV</td>\n",
       "      <td>blue</td>\n",
       "      <td>ny</td>\n",
       "      <td>16553</td>\n",
       "      <td>6359.284668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>redding</td>\n",
       "      <td>2005</td>\n",
       "      <td>ford</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>144554</td>\n",
       "      <td>clean</td>\n",
       "      <td>manual</td>\n",
       "      <td>fwd</td>\n",
       "      <td>mid-size</td>\n",
       "      <td>sedan</td>\n",
       "      <td>red</td>\n",
       "      <td>ca</td>\n",
       "      <td>5158</td>\n",
       "      <td>3979.386230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           region  year manufacturer  condition    cylinders fuel  odometer  \\\n",
       "id                                                                            \n",
       "0       nashville  1949          bmw  excellent  6 cylinders  gas    115148   \n",
       "1   state college  2013       toyota       fair  8 cylinders  gas    172038   \n",
       "2         wichita  1998         ford       good  6 cylinders  gas    152492   \n",
       "3          albany  2014         ford  excellent  4 cylinders  gas    104118   \n",
       "4         redding  2005         ford  excellent  6 cylinders  gas    144554   \n",
       "\n",
       "   title_status transmission drive       size         type paint_color state  \\\n",
       "id                                                                             \n",
       "0         clean       manual   rwd   mid-size  convertible      orange   NaN   \n",
       "1         clean    automatic   rwd  full-size        sedan      silver    pa   \n",
       "2         clean    automatic   fwd  full-size          SUV      silver    ks   \n",
       "3         clean       manual   fwd   mid-size          SUV        blue    ny   \n",
       "4         clean       manual   fwd   mid-size        sedan         red    ca   \n",
       "\n",
       "    price          oof  \n",
       "id                      \n",
       "0   27587  5858.745117  \n",
       "1    4724  3304.864746  \n",
       "2   10931  4112.928223  \n",
       "3   16553  6359.284668  \n",
       "4    5158  3979.386230  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df = train.copy()\n",
    "oof_df['oof'] = oof\n",
    "oof_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4694855439000568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x37d049110>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(mean_absolute_percentage_error(y, oof))\n",
    "plt.scatter(y, oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27532</td>\n",
       "      <td>6961.747925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27533</td>\n",
       "      <td>4870.367798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27534</td>\n",
       "      <td>5605.261108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27535</td>\n",
       "      <td>17531.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27536</td>\n",
       "      <td>4320.296265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27532</th>\n",
       "      <td>55064</td>\n",
       "      <td>9249.024170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27533</th>\n",
       "      <td>55065</td>\n",
       "      <td>12653.056885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27534</th>\n",
       "      <td>55066</td>\n",
       "      <td>7246.430786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27535</th>\n",
       "      <td>55067</td>\n",
       "      <td>4415.756348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27536</th>\n",
       "      <td>55068</td>\n",
       "      <td>4542.998413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27537 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id         price\n",
       "0      27532   6961.747925\n",
       "1      27533   4870.367798\n",
       "2      27534   5605.261108\n",
       "3      27535  17531.593750\n",
       "4      27536   4320.296265\n",
       "...      ...           ...\n",
       "27532  55064   9249.024170\n",
       "27533  55065  12653.056885\n",
       "27534  55066   7246.430786\n",
       "27535  55067   4415.756348\n",
       "27536  55068   4542.998413\n",
       "\n",
       "[27537 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame({\"id\":test.index})\n",
    "sub_df[\"price\"] = predictions\n",
    "sub_df.to_csv('output/sub003.csv', index=False, header=False)\n",
    "sub_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
